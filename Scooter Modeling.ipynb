{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Scooter Modeling.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FsKJ3vx-dtiD","executionInfo":{"status":"ok","timestamp":1607546949807,"user_tz":360,"elapsed":17729,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"4eb95e2c-dbd3-4e00-ae00-f3936b1954ea"},"source":["%matplotlib inline\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","import seaborn as sns\n","from datetime import datetime\n","drive.mount('/content/drive')\n","data = pd.read_csv('/content/drive/Shared drives/bds-final-project/scooter_data_clean.csv', index_col=0)\n","merge_data = pd.read_csv('/content/drive/Shared drives/bds-final-project/merged_data.csv', index_col=0)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  mask |= (ar1 == a)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"A7ydVOFFeEWp","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1607546978986,"user_tz":360,"elapsed":46897,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"19515fe1-4545-4577-9a18-e3c9843f554e"},"source":["data['date_of_month'] = [datetime.utcfromtimestamp(date).strftime('%d') for date in data[\"start_time\"]]\n","data.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>trip_duration</th>\n","      <th>trip_distance</th>\n","      <th>start_time</th>\n","      <th>end_time</th>\n","      <th>month</th>\n","      <th>hour</th>\n","      <th>day_of_week</th>\n","      <th>district_start</th>\n","      <th>district_end</th>\n","      <th>year</th>\n","      <th>tract_start</th>\n","      <th>tract_end</th>\n","      <th>vehicle_type_bicycle</th>\n","      <th>vehicle_type_moped</th>\n","      <th>vehicle_type_scooter</th>\n","      <th>date_of_month</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>420</td>\n","      <td>869.0</td>\n","      <td>1523390400</td>\n","      <td>1523390400</td>\n","      <td>4</td>\n","      <td>20</td>\n","      <td>2</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>2018</td>\n","      <td>4.845300e+10</td>\n","      <td>4.845300e+10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>371</td>\n","      <td>1037.0</td>\n","      <td>1523389500</td>\n","      <td>1523390400</td>\n","      <td>4</td>\n","      <td>19</td>\n","      <td>2</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>2018</td>\n","      <td>4.845300e+10</td>\n","      <td>4.845300e+10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1687</td>\n","      <td>4491.0</td>\n","      <td>1524489300</td>\n","      <td>1524491100</td>\n","      <td>4</td>\n","      <td>13</td>\n","      <td>1</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>2018</td>\n","      <td>4.845300e+10</td>\n","      <td>4.845300e+10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>524</td>\n","      <td>633.0</td>\n","      <td>1524865500</td>\n","      <td>1524866400</td>\n","      <td>4</td>\n","      <td>21</td>\n","      <td>5</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>2018</td>\n","      <td>4.845300e+10</td>\n","      <td>4.845300e+10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>322</td>\n","      <td>1114.0</td>\n","      <td>1524865500</td>\n","      <td>1524865500</td>\n","      <td>4</td>\n","      <td>21</td>\n","      <td>5</td>\n","      <td>9.0</td>\n","      <td>9.0</td>\n","      <td>2018</td>\n","      <td>4.845300e+10</td>\n","      <td>4.845300e+10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>27</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   trip_duration  trip_distance  ...  vehicle_type_scooter  date_of_month\n","0            420          869.0  ...                     1             10\n","1            371         1037.0  ...                     1             10\n","2           1687         4491.0  ...                     1             23\n","3            524          633.0  ...                     1             27\n","4            322         1114.0  ...                     1             27\n","\n","[5 rows x 16 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"vWWs75QkPgWi","executionInfo":{"status":"ok","timestamp":1607546978992,"user_tz":360,"elapsed":46883,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"a382a90b-c7c4-471f-9dc9-4fad6af2acc5"},"source":["month_dict = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May' ,6: 'Jun', 7: 'Jul',8:'Aug' ,9: 'Sept', 10: 'Oct', 11: 'Nov',12: 'Dec'}\n","weekday_dict = {0: 'Sun', 1: 'Mon', 2: 'Tues', 3: 'Wed', 4: 'Thur', 5:'Fri', 6: 'Sat'}\n","\n","merge_data = pd.read_csv('/content/drive/Shared drives/bds-final-project/merged_data.csv', index_col=0)\n","merge_data[\"weekday\"] = [weekday_dict[num] for num in merge_data.day_of_week]\n","merge_data[\"month\"] = [month_dict[datetime.strptime(strDate, '%Y-%m-%d').month] for strDate in merge_data.date]\n","merge_data[\"year\"] = [datetime.strptime(strDate, '%Y-%m-%d').year for strDate in merge_data.date]\n","merge_data[\"date_of_month\"] = [datetime.strptime(strDate, '%Y-%m-%d').day for strDate in merge_data.date]\n","merge_data[\"num_trips\"] = merge_data.num_bicycle_trips + merge_data.num_moped_trips + merge_data.num_scooter_trips\n","merge_data[\"prev_day_trips\"] = merge_data[\"num_trips\"].shift(periods=1, fill_value=0)\n","merge_data = merge_data.drop([\"date\", \"day_of_week\", \"num_bicycle_trips\", \"num_moped_trips\", \"num_scooter_trips\"], axis=1)\n","merge_data.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>avg_trip_duration</th>\n","      <th>avg_trip_distance</th>\n","      <th>Max_Temperature_F</th>\n","      <th>Avg_Temperature_F</th>\n","      <th>Min_Temperature_F</th>\n","      <th>Max_DewPoint_F</th>\n","      <th>Avg_DewPoint_F</th>\n","      <th>Min_DewPoint_F</th>\n","      <th>Max_Humidity_%</th>\n","      <th>Avg_Humidity_%</th>\n","      <th>Min_Humidity_%</th>\n","      <th>Max_WindSpeed_mph</th>\n","      <th>Avg_WindSpeed_mph</th>\n","      <th>Min_WindSpeed_mph</th>\n","      <th>Max_Pressure_Hg</th>\n","      <th>Avg_Pressure_Hg</th>\n","      <th>Min_Pressure_Hg</th>\n","      <th>Precipitation_inches</th>\n","      <th>weekday</th>\n","      <th>month</th>\n","      <th>year</th>\n","      <th>date_of_month</th>\n","      <th>num_trips</th>\n","      <th>prev_day_trips</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>943.000000</td>\n","      <td>419.000000</td>\n","      <td>80</td>\n","      <td>72.7</td>\n","      <td>65</td>\n","      <td>71</td>\n","      <td>64.4</td>\n","      <td>40</td>\n","      <td>90</td>\n","      <td>76.6</td>\n","      <td>40</td>\n","      <td>24</td>\n","      <td>12.1</td>\n","      <td>0</td>\n","      <td>29.5</td>\n","      <td>29.2</td>\n","      <td>29.1</td>\n","      <td>0.00</td>\n","      <td>Tues</td>\n","      <td>Apr</td>\n","      <td>2018</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1360.333333</td>\n","      <td>5691.333333</td>\n","      <td>70</td>\n","      <td>59.8</td>\n","      <td>50</td>\n","      <td>49</td>\n","      <td>35.1</td>\n","      <td>30</td>\n","      <td>80</td>\n","      <td>41.6</td>\n","      <td>26</td>\n","      <td>28</td>\n","      <td>13.5</td>\n","      <td>0</td>\n","      <td>29.7</td>\n","      <td>29.6</td>\n","      <td>29.5</td>\n","      <td>0.00</td>\n","      <td>Wed</td>\n","      <td>Apr</td>\n","      <td>2018</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1198.633929</td>\n","      <td>2238.776786</td>\n","      <td>78</td>\n","      <td>68.0</td>\n","      <td>56</td>\n","      <td>67</td>\n","      <td>57.6</td>\n","      <td>47</td>\n","      <td>87</td>\n","      <td>70.0</td>\n","      <td>56</td>\n","      <td>16</td>\n","      <td>9.0</td>\n","      <td>0</td>\n","      <td>29.6</td>\n","      <td>29.4</td>\n","      <td>29.3</td>\n","      <td>0.00</td>\n","      <td>Thur</td>\n","      <td>Apr</td>\n","      <td>2018</td>\n","      <td>5</td>\n","      <td>112</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1118.914530</td>\n","      <td>2616.518519</td>\n","      <td>85</td>\n","      <td>75.6</td>\n","      <td>71</td>\n","      <td>71</td>\n","      <td>68.7</td>\n","      <td>67</td>\n","      <td>93</td>\n","      <td>80.1</td>\n","      <td>58</td>\n","      <td>22</td>\n","      <td>12.4</td>\n","      <td>3</td>\n","      <td>29.3</td>\n","      <td>29.2</td>\n","      <td>29.1</td>\n","      <td>0.00</td>\n","      <td>Fri</td>\n","      <td>Apr</td>\n","      <td>2018</td>\n","      <td>6</td>\n","      <td>351</td>\n","      <td>112</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>970.707207</td>\n","      <td>1815.882883</td>\n","      <td>72</td>\n","      <td>50.0</td>\n","      <td>41</td>\n","      <td>69</td>\n","      <td>44.6</td>\n","      <td>35</td>\n","      <td>96</td>\n","      <td>81.6</td>\n","      <td>73</td>\n","      <td>28</td>\n","      <td>18.4</td>\n","      <td>12</td>\n","      <td>29.5</td>\n","      <td>29.4</td>\n","      <td>29.2</td>\n","      <td>0.31</td>\n","      <td>Sat</td>\n","      <td>Apr</td>\n","      <td>2018</td>\n","      <td>7</td>\n","      <td>222</td>\n","      <td>351</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   avg_trip_duration  avg_trip_distance  ...  num_trips  prev_day_trips\n","0         943.000000         419.000000  ...          1               0\n","1        1360.333333        5691.333333  ...          3               1\n","2        1198.633929        2238.776786  ...        112               3\n","3        1118.914530        2616.518519  ...        351             112\n","4         970.707207        1815.882883  ...        222             351\n","\n","[5 rows x 24 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"96U8mvhDRQPU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607546978993,"user_tz":360,"elapsed":46870,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"97609007-89e0-4d1e-f12e-0388def45446"},"source":["###NOTE: Testing for report purposes. You can COMMENT and UNCOMMENT this line to utilize weather data\n","\n","#merge_data = merge_data[[\"weekday\", \"month\", \"year\", \"date_of_month\", \"num_trips\", \"prev_day_trips\", \"avg_trip_duration\", \"avg_trip_distance\"]]\n","#merge_data = merge_data[[\"weekday\", \"month\", \"year\", \"date_of_month\", \"num_trips\", \"prev_day_trips\", \"avg_trip_duration\", \"avg_trip_distance\", \"Avg_Temperature_F\"]]\n","sum(merge_data[\"num_trips\"])/len(merge_data)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6819.658620689655"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"WGs_ydhma4Tz","executionInfo":{"status":"ok","timestamp":1607546978994,"user_tz":360,"elapsed":46857,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"39f03544-81ba-4950-e3e3-5dd9faff34bc"},"source":["weekday_dums = pd.get_dummies(merge_data[\"weekday\"], prefix=\"day_\")\n","month_dums = pd.get_dummies(merge_data[\"month\"], prefix=\"mo_\")\n","merge_data = pd.concat((merge_data, weekday_dums, month_dums), axis=1).drop([\"weekday\", \"month\"], axis=1)\n","merge_data.head()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>avg_trip_duration</th>\n","      <th>avg_trip_distance</th>\n","      <th>Max_Temperature_F</th>\n","      <th>Avg_Temperature_F</th>\n","      <th>Min_Temperature_F</th>\n","      <th>Max_DewPoint_F</th>\n","      <th>Avg_DewPoint_F</th>\n","      <th>Min_DewPoint_F</th>\n","      <th>Max_Humidity_%</th>\n","      <th>Avg_Humidity_%</th>\n","      <th>Min_Humidity_%</th>\n","      <th>Max_WindSpeed_mph</th>\n","      <th>Avg_WindSpeed_mph</th>\n","      <th>Min_WindSpeed_mph</th>\n","      <th>Max_Pressure_Hg</th>\n","      <th>Avg_Pressure_Hg</th>\n","      <th>Min_Pressure_Hg</th>\n","      <th>Precipitation_inches</th>\n","      <th>year</th>\n","      <th>date_of_month</th>\n","      <th>num_trips</th>\n","      <th>prev_day_trips</th>\n","      <th>day__Fri</th>\n","      <th>day__Mon</th>\n","      <th>day__Sat</th>\n","      <th>day__Sun</th>\n","      <th>day__Thur</th>\n","      <th>day__Tues</th>\n","      <th>day__Wed</th>\n","      <th>mo__Apr</th>\n","      <th>mo__Aug</th>\n","      <th>mo__Dec</th>\n","      <th>mo__Feb</th>\n","      <th>mo__Jan</th>\n","      <th>mo__Jul</th>\n","      <th>mo__Jun</th>\n","      <th>mo__Mar</th>\n","      <th>mo__May</th>\n","      <th>mo__Nov</th>\n","      <th>mo__Oct</th>\n","      <th>mo__Sept</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>943.000000</td>\n","      <td>419.000000</td>\n","      <td>80</td>\n","      <td>72.7</td>\n","      <td>65</td>\n","      <td>71</td>\n","      <td>64.4</td>\n","      <td>40</td>\n","      <td>90</td>\n","      <td>76.6</td>\n","      <td>40</td>\n","      <td>24</td>\n","      <td>12.1</td>\n","      <td>0</td>\n","      <td>29.5</td>\n","      <td>29.2</td>\n","      <td>29.1</td>\n","      <td>0.00</td>\n","      <td>2018</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1360.333333</td>\n","      <td>5691.333333</td>\n","      <td>70</td>\n","      <td>59.8</td>\n","      <td>50</td>\n","      <td>49</td>\n","      <td>35.1</td>\n","      <td>30</td>\n","      <td>80</td>\n","      <td>41.6</td>\n","      <td>26</td>\n","      <td>28</td>\n","      <td>13.5</td>\n","      <td>0</td>\n","      <td>29.7</td>\n","      <td>29.6</td>\n","      <td>29.5</td>\n","      <td>0.00</td>\n","      <td>2018</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1198.633929</td>\n","      <td>2238.776786</td>\n","      <td>78</td>\n","      <td>68.0</td>\n","      <td>56</td>\n","      <td>67</td>\n","      <td>57.6</td>\n","      <td>47</td>\n","      <td>87</td>\n","      <td>70.0</td>\n","      <td>56</td>\n","      <td>16</td>\n","      <td>9.0</td>\n","      <td>0</td>\n","      <td>29.6</td>\n","      <td>29.4</td>\n","      <td>29.3</td>\n","      <td>0.00</td>\n","      <td>2018</td>\n","      <td>5</td>\n","      <td>112</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1118.914530</td>\n","      <td>2616.518519</td>\n","      <td>85</td>\n","      <td>75.6</td>\n","      <td>71</td>\n","      <td>71</td>\n","      <td>68.7</td>\n","      <td>67</td>\n","      <td>93</td>\n","      <td>80.1</td>\n","      <td>58</td>\n","      <td>22</td>\n","      <td>12.4</td>\n","      <td>3</td>\n","      <td>29.3</td>\n","      <td>29.2</td>\n","      <td>29.1</td>\n","      <td>0.00</td>\n","      <td>2018</td>\n","      <td>6</td>\n","      <td>351</td>\n","      <td>112</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>970.707207</td>\n","      <td>1815.882883</td>\n","      <td>72</td>\n","      <td>50.0</td>\n","      <td>41</td>\n","      <td>69</td>\n","      <td>44.6</td>\n","      <td>35</td>\n","      <td>96</td>\n","      <td>81.6</td>\n","      <td>73</td>\n","      <td>28</td>\n","      <td>18.4</td>\n","      <td>12</td>\n","      <td>29.5</td>\n","      <td>29.4</td>\n","      <td>29.2</td>\n","      <td>0.31</td>\n","      <td>2018</td>\n","      <td>7</td>\n","      <td>222</td>\n","      <td>351</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   avg_trip_duration  avg_trip_distance  ...  mo__Oct  mo__Sept\n","0         943.000000         419.000000  ...        0         0\n","1        1360.333333        5691.333333  ...        0         0\n","2        1198.633929        2238.776786  ...        0         0\n","3        1118.914530        2616.518519  ...        0         0\n","4         970.707207        1815.882883  ...        0         0\n","\n","[5 rows x 41 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"UHwYpzdOJEXz","executionInfo":{"status":"ok","timestamp":1607546979845,"user_tz":360,"elapsed":47694,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}}},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from sklearn.linear_model import LinearRegression, ElasticNet, Lasso\n","\n","mergeX = merge_data.drop([\"num_trips\", \"avg_trip_duration\", \"avg_trip_distance\"], axis=1)\n","mergeY = merge_data[\"num_trips\"]\n","xTrain, xTest, yTrain, yTest = train_test_split(mergeX, mergeY, test_size = .30, random_state=42)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DlL8cp4DKGWu","executionInfo":{"status":"ok","timestamp":1607546979847,"user_tz":360,"elapsed":47675,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"b6c8c0ea-b150-42a7-a4d5-3e2b9993d2a1"},"source":["#note: adding in a lag of the previous day's trip count was VERY helpful, MSE went from ~52M to ~25M\n","regressor = LinearRegression().fit(xTrain, yTrain)\n","print(\"Train MSE: \", mean_squared_error(yTrain, regressor.predict(xTrain)))\n","print(\"Test MSE:  \", mean_squared_error(yTest, regressor.predict(xTest)))\n","print(\"Test MAE:  \", mean_absolute_error(yTest, regressor.predict(xTest)))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Train MSE:  22812295.272823997\n","Test MSE:   25266191.530140836\n","Test MAE:   3771.150176520922\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"z3ShAbnm4T5K"},"source":["Above output using all weather data:\n","\n","*   Train MSE:  22,812,295.272823997 \n","*   Test MSE:   25,266,191.530140836\n","*   Test MAE:   3,771.150176520922\n","\n","Above output using no weather data:\n","*   Train MSE:  23,798,786.280165028\n","*   Test MSE:   24,339,304.335490588\n","*   Test MAE:   3,648.2655441582515\n","\n","Using only average temperature\n","Train MSE:  23753901.401045088\n","Test MSE:   24237005.647708174\n","Test MAE:   3647.7563410562334\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bi7PgPDMKGc-","executionInfo":{"status":"ok","timestamp":1607546979848,"user_tz":360,"elapsed":47665,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"17c54343-da24-4897-8adc-8d2105415664"},"source":["for i in range(len(regressor.coef_)):\n","  print(xTrain.columns[i] + \": \" + str(regressor.coef_[i]))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Max_Temperature_F: -98.62170127927739\n","Avg_Temperature_F: -182.05342170605329\n","Min_Temperature_F: -88.7061615345335\n","Max_DewPoint_F: -17.724972091687444\n","Avg_DewPoint_F: 398.4457187202553\n","Min_DewPoint_F: 8.587545222553748\n","Max_Humidity_%: -12.74778683065539\n","Avg_Humidity_%: -148.02389986390997\n","Min_Humidity_%: -63.672389262900715\n","Max_WindSpeed_mph: 74.40614167329103\n","Avg_WindSpeed_mph: -191.07333051247022\n","Min_WindSpeed_mph: 4.0670216252780405\n","Max_Pressure_Hg: -549.2305147225235\n","Avg_Pressure_Hg: -3147.6591744861303\n","Min_Pressure_Hg: 457.2346435874515\n","Precipitation_inches: 1543.8400509203825\n","year: -2053.746755706957\n","date_of_month: 2.96449565877685\n","prev_day_trips: 0.6655747479204818\n","day__Fri: 1550.4379391775676\n","day__Mon: -1135.9553744280054\n","day__Sat: 1480.1169970048522\n","day__Sun: -1931.25073632395\n","day__Thur: 416.6132017911616\n","day__Tues: -355.42613986177025\n","day__Wed: -24.535887359861007\n","mo__Apr: -883.9513088213436\n","mo__Aug: -372.4282934633772\n","mo__Dec: -1253.918994416428\n","mo__Feb: 1093.612454641705\n","mo__Jan: 584.3888646098386\n","mo__Jul: -649.4747735995006\n","mo__Jun: -1251.0839982045309\n","mo__Mar: 1492.7237449554082\n","mo__May: -359.8626983051063\n","mo__Nov: 92.69545319970285\n","mo__Oct: 888.3533454676831\n","mo__Sept: 618.9462039359319\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U1HBl588KGfX","executionInfo":{"status":"ok","timestamp":1607546999226,"user_tz":360,"elapsed":67033,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"fb760fea-3d9d-41b2-d8f4-2a879e816cc4"},"source":["#next, hyperparameter tune the regression and then re-report outcomes\n","from sklearn.model_selection import GridSearchCV\n","\n","params = {\n","    'l1_ratio':[0,.2,.4,.6,.8,1],\n","    'random_state':[42],\n","    'alpha':[.25, .5, .75, 1, 5],\n","    'max_iter':[10000]\n","}\n","clf = ElasticNet()\n","grid = GridSearchCV(clf, params, verbose=3).fit(xTrain,yTrain)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Fitting 5 folds for each of 30 candidates, totalling 150 fits\n","[CV] alpha=0.25, l1_ratio=0, max_iter=10000, random_state=42 .........\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10276974369.759796, tolerance: 5095063.584411824\n","  positive)\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=0.25, l1_ratio=0, max_iter=10000, random_state=42, score=0.675, total=   0.4s\n","[CV] alpha=0.25, l1_ratio=0, max_iter=10000, random_state=42 .........\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10248707861.212292, tolerance: 5422651.369414163\n","  positive)\n","[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=0.25, l1_ratio=0, max_iter=10000, random_state=42, score=0.583, total=   0.4s\n","[CV] alpha=0.25, l1_ratio=0, max_iter=10000, random_state=42 .........\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9702163240.26782, tolerance: 5139301.218206405\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=0.25, l1_ratio=0, max_iter=10000, random_state=42, score=0.585, total=   0.4s\n","[CV] alpha=0.25, l1_ratio=0, max_iter=10000, random_state=42 .........\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10563402974.851118, tolerance: 5509039.273388546\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=0.25, l1_ratio=0, max_iter=10000, random_state=42, score=0.604, total=   0.4s\n","[CV] alpha=0.25, l1_ratio=0, max_iter=10000, random_state=42 .........\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9554081092.23263, tolerance: 5140903.467703449\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=0.25, l1_ratio=0, max_iter=10000, random_state=42, score=0.567, total=   0.4s\n","[CV] alpha=0.25, l1_ratio=0.2, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.672, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.2, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.586, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.2, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.588, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.2, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.607, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.2, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.571, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.4, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.668, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.4, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.591, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.4, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.590, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.4, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.611, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.4, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.575, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.6, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.660, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.6, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.596, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.6, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.593, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.6, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.615, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.6, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.579, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.8, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.641, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.8, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.603, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.8, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.596, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.8, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.621, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=0.8, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.25, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.585, total=   0.1s\n","[CV] alpha=0.25, l1_ratio=1, max_iter=10000, random_state=42 .........\n","[CV]  alpha=0.25, l1_ratio=1, max_iter=10000, random_state=42, score=0.608, total=   0.2s\n","[CV] alpha=0.25, l1_ratio=1, max_iter=10000, random_state=42 .........\n","[CV]  alpha=0.25, l1_ratio=1, max_iter=10000, random_state=42, score=0.606, total=   0.2s\n","[CV] alpha=0.25, l1_ratio=1, max_iter=10000, random_state=42 .........\n","[CV]  alpha=0.25, l1_ratio=1, max_iter=10000, random_state=42, score=0.591, total=   0.2s\n","[CV] alpha=0.25, l1_ratio=1, max_iter=10000, random_state=42 .........\n","[CV]  alpha=0.25, l1_ratio=1, max_iter=10000, random_state=42, score=0.623, total=   0.2s\n","[CV] alpha=0.25, l1_ratio=1, max_iter=10000, random_state=42 .........\n","[CV]  alpha=0.25, l1_ratio=1, max_iter=10000, random_state=42, score=0.590, total=   0.2s\n","[CV] alpha=0.5, l1_ratio=0, max_iter=10000, random_state=42 ..........\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10535312730.79669, tolerance: 5095063.584411824\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=0.5, l1_ratio=0, max_iter=10000, random_state=42, score=0.679, total=   0.4s\n","[CV] alpha=0.5, l1_ratio=0, max_iter=10000, random_state=42 ..........\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10429498178.938179, tolerance: 5422651.369414163\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=0.5, l1_ratio=0, max_iter=10000, random_state=42, score=0.571, total=   0.4s\n","[CV] alpha=0.5, l1_ratio=0, max_iter=10000, random_state=42 ..........\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9902705492.435438, tolerance: 5139301.218206405\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=0.5, l1_ratio=0, max_iter=10000, random_state=42, score=0.578, total=   0.4s\n","[CV] alpha=0.5, l1_ratio=0, max_iter=10000, random_state=42 ..........\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10774030837.071522, tolerance: 5509039.273388546\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=0.5, l1_ratio=0, max_iter=10000, random_state=42, score=0.595, total=   0.4s\n","[CV] alpha=0.5, l1_ratio=0, max_iter=10000, random_state=42 ..........\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9730942086.848436, tolerance: 5140903.467703449\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=0.5, l1_ratio=0, max_iter=10000, random_state=42, score=0.557, total=   0.4s\n","[CV] alpha=0.5, l1_ratio=0.2, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.678, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.2, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.574, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.2, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.580, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.2, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.598, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.2, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.560, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.4, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.676, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.4, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.579, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.4, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.583, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.4, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.602, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.4, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.565, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.6, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.672, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.6, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.586, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.6, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.588, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.6, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.607, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.6, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.571, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.8, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.660, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.8, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.596, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.8, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.593, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.8, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.615, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=0.8, max_iter=10000, random_state=42 ........\n","[CV]  alpha=0.5, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.579, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=1, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=0.5, l1_ratio=1, max_iter=10000, random_state=42, score=0.624, total=   0.2s\n","[CV] alpha=0.5, l1_ratio=1, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=0.5, l1_ratio=1, max_iter=10000, random_state=42, score=0.606, total=   0.2s\n","[CV] alpha=0.5, l1_ratio=1, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=0.5, l1_ratio=1, max_iter=10000, random_state=42, score=0.591, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=1, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=0.5, l1_ratio=1, max_iter=10000, random_state=42, score=0.623, total=   0.1s\n","[CV] alpha=0.5, l1_ratio=1, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=0.5, l1_ratio=1, max_iter=10000, random_state=42, score=0.590, total=   0.2s\n","[CV] alpha=0.75, l1_ratio=0, max_iter=10000, random_state=42 .........\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10662307754.591595, tolerance: 5095063.584411824\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=0.75, l1_ratio=0, max_iter=10000, random_state=42, score=0.680, total=   0.4s\n","[CV] alpha=0.75, l1_ratio=0, max_iter=10000, random_state=42 .........\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10518734043.936333, tolerance: 5422651.369414163\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=0.75, l1_ratio=0, max_iter=10000, random_state=42, score=0.564, total=   0.4s\n","[CV] alpha=0.75, l1_ratio=0, max_iter=10000, random_state=42 .........\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10001206446.100817, tolerance: 5139301.218206405\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=0.75, l1_ratio=0, max_iter=10000, random_state=42, score=0.573, total=   0.4s\n","[CV] alpha=0.75, l1_ratio=0, max_iter=10000, random_state=42 .........\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10880507270.825617, tolerance: 5509039.273388546\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=0.75, l1_ratio=0, max_iter=10000, random_state=42, score=0.590, total=   0.4s\n","[CV] alpha=0.75, l1_ratio=0, max_iter=10000, random_state=42 .........\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9818458730.103678, tolerance: 5140903.467703449\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=0.75, l1_ratio=0, max_iter=10000, random_state=42, score=0.551, total=   0.4s\n","[CV] alpha=0.75, l1_ratio=0.2, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.679, total=   0.0s\n","[CV] alpha=0.75, l1_ratio=0.2, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.568, total=   0.1s\n","[CV] alpha=0.75, l1_ratio=0.2, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.576, total=   0.0s\n","[CV] alpha=0.75, l1_ratio=0.2, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.593, total=   0.0s\n","[CV] alpha=0.75, l1_ratio=0.2, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.554, total=   0.1s\n","[CV] alpha=0.75, l1_ratio=0.4, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.679, total=   0.0s\n","[CV] alpha=0.75, l1_ratio=0.4, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.572, total=   0.0s\n","[CV] alpha=0.75, l1_ratio=0.4, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.579, total=   0.1s\n","[CV] alpha=0.75, l1_ratio=0.4, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.596, total=   0.0s\n","[CV] alpha=0.75, l1_ratio=0.4, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.559, total=   0.1s\n","[CV] alpha=0.75, l1_ratio=0.6, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.676, total=   0.1s\n","[CV] alpha=0.75, l1_ratio=0.6, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.579, total=   0.1s\n","[CV] alpha=0.75, l1_ratio=0.6, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.583, total=   0.0s\n","[CV] alpha=0.75, l1_ratio=0.6, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.602, total=   0.1s\n","[CV] alpha=0.75, l1_ratio=0.6, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.565, total=   0.1s\n","[CV] alpha=0.75, l1_ratio=0.8, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.668, total=   0.1s\n","[CV] alpha=0.75, l1_ratio=0.8, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.591, total=   0.1s\n","[CV] alpha=0.75, l1_ratio=0.8, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.590, total=   0.1s\n","[CV] alpha=0.75, l1_ratio=0.8, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.611, total=   0.1s\n","[CV] alpha=0.75, l1_ratio=0.8, max_iter=10000, random_state=42 .......\n","[CV]  alpha=0.75, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.575, total=   0.1s\n","[CV] alpha=0.75, l1_ratio=1, max_iter=10000, random_state=42 .........\n","[CV]  alpha=0.75, l1_ratio=1, max_iter=10000, random_state=42, score=0.638, total=   0.1s\n","[CV] alpha=0.75, l1_ratio=1, max_iter=10000, random_state=42 .........\n","[CV]  alpha=0.75, l1_ratio=1, max_iter=10000, random_state=42, score=0.606, total=   0.2s\n","[CV] alpha=0.75, l1_ratio=1, max_iter=10000, random_state=42 .........\n","[CV]  alpha=0.75, l1_ratio=1, max_iter=10000, random_state=42, score=0.591, total=   0.1s\n","[CV] alpha=0.75, l1_ratio=1, max_iter=10000, random_state=42 .........\n","[CV]  alpha=0.75, l1_ratio=1, max_iter=10000, random_state=42, score=0.623, total=   0.1s\n","[CV] alpha=0.75, l1_ratio=1, max_iter=10000, random_state=42 .........\n","[CV]  alpha=0.75, l1_ratio=1, max_iter=10000, random_state=42, score=0.590, total=   0.1s\n","[CV] alpha=1, l1_ratio=0, max_iter=10000, random_state=42 ............\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10739750321.61819, tolerance: 5095063.584411824\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=1, l1_ratio=0, max_iter=10000, random_state=42, score=0.680, total=   0.4s\n","[CV] alpha=1, l1_ratio=0, max_iter=10000, random_state=42 ............\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10573260390.48779, tolerance: 5422651.369414163\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=1, l1_ratio=0, max_iter=10000, random_state=42, score=0.560, total=   0.4s\n","[CV] alpha=1, l1_ratio=0, max_iter=10000, random_state=42 ............\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10061120033.874685, tolerance: 5139301.218206405\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=1, l1_ratio=0, max_iter=10000, random_state=42, score=0.570, total=   0.4s\n","[CV] alpha=1, l1_ratio=0, max_iter=10000, random_state=42 ............\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10946748392.638012, tolerance: 5509039.273388546\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=1, l1_ratio=0, max_iter=10000, random_state=42, score=0.588, total=   0.4s\n","[CV] alpha=1, l1_ratio=0, max_iter=10000, random_state=42 ............\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9872123920.166103, tolerance: 5140903.467703449\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=1, l1_ratio=0, max_iter=10000, random_state=42, score=0.548, total=   0.4s\n","[CV] alpha=1, l1_ratio=0.2, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.680, total=   0.0s\n","[CV] alpha=1, l1_ratio=0.2, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.563, total=   0.0s\n","[CV] alpha=1, l1_ratio=0.2, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.573, total=   0.0s\n","[CV] alpha=1, l1_ratio=0.2, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.590, total=   0.0s\n","[CV] alpha=1, l1_ratio=0.2, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.551, total=   0.0s\n","[CV] alpha=1, l1_ratio=0.4, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.679, total=   0.1s\n","[CV] alpha=1, l1_ratio=0.4, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.568, total=   0.0s\n","[CV] alpha=1, l1_ratio=0.4, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.576, total=   0.0s\n","[CV] alpha=1, l1_ratio=0.4, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.593, total=   0.0s\n","[CV] alpha=1, l1_ratio=0.4, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.554, total=   0.0s\n","[CV] alpha=1, l1_ratio=0.6, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.678, total=   0.0s\n","[CV] alpha=1, l1_ratio=0.6, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.574, total=   0.0s\n","[CV] alpha=1, l1_ratio=0.6, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.580, total=   0.0s\n","[CV] alpha=1, l1_ratio=0.6, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.598, total=   0.0s\n","[CV] alpha=1, l1_ratio=0.6, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.560, total=   0.0s\n","[CV] alpha=1, l1_ratio=0.8, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.672, total=   0.1s\n","[CV] alpha=1, l1_ratio=0.8, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.586, total=   0.1s\n","[CV] alpha=1, l1_ratio=0.8, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.588, total=   0.1s\n","[CV] alpha=1, l1_ratio=0.8, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.607, total=   0.1s\n","[CV] alpha=1, l1_ratio=0.8, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=1, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.571, total=   0.0s\n","[CV] alpha=1, l1_ratio=1, max_iter=10000, random_state=42 ............\n","[CV]  alpha=1, l1_ratio=1, max_iter=10000, random_state=42, score=0.648, total=   0.1s\n","[CV] alpha=1, l1_ratio=1, max_iter=10000, random_state=42 ............\n","[CV]  alpha=1, l1_ratio=1, max_iter=10000, random_state=42, score=0.607, total=   0.2s\n","[CV] alpha=1, l1_ratio=1, max_iter=10000, random_state=42 ............\n","[CV]  alpha=1, l1_ratio=1, max_iter=10000, random_state=42, score=0.591, total=   0.1s\n","[CV] alpha=1, l1_ratio=1, max_iter=10000, random_state=42 ............\n","[CV]  alpha=1, l1_ratio=1, max_iter=10000, random_state=42, score=0.623, total=   0.1s\n","[CV] alpha=1, l1_ratio=1, max_iter=10000, random_state=42 ............\n","[CV]  alpha=1, l1_ratio=1, max_iter=10000, random_state=42, score=0.590, total=   0.1s\n","[CV] alpha=5, l1_ratio=0, max_iter=10000, random_state=42 ............\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11005192566.768827, tolerance: 5095063.584411824\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=5, l1_ratio=0, max_iter=10000, random_state=42, score=0.678, total=   0.4s\n","[CV] alpha=5, l1_ratio=0, max_iter=10000, random_state=42 ............\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10760675314.060575, tolerance: 5422651.369414163\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=5, l1_ratio=0, max_iter=10000, random_state=42, score=0.546, total=   0.4s\n","[CV] alpha=5, l1_ratio=0, max_iter=10000, random_state=42 ............\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10263775115.751165, tolerance: 5139301.218206405\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=5, l1_ratio=0, max_iter=10000, random_state=42, score=0.560, total=   0.4s\n","[CV] alpha=5, l1_ratio=0, max_iter=10000, random_state=42 ............\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11188779391.493692, tolerance: 5509039.273388546\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=5, l1_ratio=0, max_iter=10000, random_state=42, score=0.582, total=   0.4s\n","[CV] alpha=5, l1_ratio=0, max_iter=10000, random_state=42 ............\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10058684206.682718, tolerance: 5140903.467703449\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  alpha=5, l1_ratio=0, max_iter=10000, random_state=42, score=0.536, total=   0.4s\n","[CV] alpha=5, l1_ratio=0.2, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.678, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.2, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.547, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.2, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.561, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.2, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.582, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.2, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.2, max_iter=10000, random_state=42, score=0.537, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.4, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.678, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.4, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.549, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.4, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.562, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.4, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.582, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.4, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.4, max_iter=10000, random_state=42, score=0.538, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.6, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.679, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.6, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.552, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.6, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.564, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.6, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.583, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.6, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.6, max_iter=10000, random_state=42, score=0.541, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.8, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.680, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.8, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.560, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.8, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.570, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.8, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.588, total=   0.0s\n","[CV] alpha=5, l1_ratio=0.8, max_iter=10000, random_state=42 ..........\n","[CV]  alpha=5, l1_ratio=0.8, max_iter=10000, random_state=42, score=0.548, total=   0.0s\n","[CV] alpha=5, l1_ratio=1, max_iter=10000, random_state=42 ............\n","[CV]  alpha=5, l1_ratio=1, max_iter=10000, random_state=42, score=0.641, total=   0.1s\n","[CV] alpha=5, l1_ratio=1, max_iter=10000, random_state=42 ............\n","[CV]  alpha=5, l1_ratio=1, max_iter=10000, random_state=42, score=0.610, total=   0.1s\n","[CV] alpha=5, l1_ratio=1, max_iter=10000, random_state=42 ............\n","[CV]  alpha=5, l1_ratio=1, max_iter=10000, random_state=42, score=0.592, total=   0.1s\n","[CV] alpha=5, l1_ratio=1, max_iter=10000, random_state=42 ............\n","[CV]  alpha=5, l1_ratio=1, max_iter=10000, random_state=42, score=0.624, total=   0.1s\n","[CV] alpha=5, l1_ratio=1, max_iter=10000, random_state=42 ............\n","[CV]  alpha=5, l1_ratio=1, max_iter=10000, random_state=42, score=0.590, total=   0.1s\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:   19.5s finished\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTPaLXANKGhq","executionInfo":{"status":"ok","timestamp":1607546999227,"user_tz":360,"elapsed":67024,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"134bf576-c966-4934-f6e3-bf3cb3745dbe"},"source":["grid.best_params_"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'alpha': 1, 'l1_ratio': 1, 'max_iter': 10000, 'random_state': 42}"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4NrC1M7WS4XH","executionInfo":{"status":"ok","timestamp":1607546999368,"user_tz":360,"elapsed":67156,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"1b4976a5-0717-494b-cdf0-6bf7b5888575"},"source":["#We see a very slight improvement by implementing lasso, but not anything significant\n","elastic = ElasticNet(alpha=5, l1_ratio=1, max_iter=10000, random_state=42).fit(xTrain,yTrain)\n","#elastic = Lasso(alpha=40, max_iter=10000, random_state=42).fit(xTrain,yTrain)\n","print(\"Train MSE: \", mean_squared_error(yTrain, elastic.predict(xTrain)))\n","print(\"Test MSE:  \", mean_squared_error(yTest, elastic.predict(xTest)))\n","print(\"Test MAE:  \", mean_absolute_error(yTest, elastic.predict(xTest)))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Train MSE:  22824595.816311292\n","Test MSE:   25192882.821143743\n","Test MAE:   3753.906150590701\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uL_JMl4XS4co","executionInfo":{"status":"ok","timestamp":1607546999369,"user_tz":360,"elapsed":67154,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}}},"source":[""],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rMiAZhAJKGw3"},"source":["This is using the non-merged data. Please note following code only for reference and review purposes, not complete analysis"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"id":"7qAhrZMDu0DV","executionInfo":{"status":"ok","timestamp":1607547002361,"user_tz":360,"elapsed":70128,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"67cfc932-b4ba-44a8-cdb6-56c9a888dabf"},"source":["grouped_data = data.groupby(['year','month', 'date_of_month']).agg({'vehicle_type_bicycle':['sum'],'vehicle_type_moped':['sum'],'vehicle_type_scooter':['sum'],\n","                                                                    'day_of_week':['mean'], 'hour':['mean'],'trip_duration':['sum'], 'trip_distance':['mean'],\n","                                                                    'district_start':['count']}).reset_index()\n","grouped_data.columns = ['year', 'month', 'date_of_month', 'num_bicycle', 'num_moped', 'num_scooter', 'weekday', 'average_trip_hour', 'total_duration', 'mean_distance', 'num_trips']\n","\n","grouped_data.head(3)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>date_of_month</th>\n","      <th>num_bicycle</th>\n","      <th>num_moped</th>\n","      <th>num_scooter</th>\n","      <th>weekday</th>\n","      <th>average_trip_hour</th>\n","      <th>total_duration</th>\n","      <th>mean_distance</th>\n","      <th>num_trips</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2018</td>\n","      <td>4</td>\n","      <td>03</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>18.000000</td>\n","      <td>943</td>\n","      <td>419.000000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2018</td>\n","      <td>4</td>\n","      <td>04</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>3.0</td>\n","      <td>14.000000</td>\n","      <td>4081</td>\n","      <td>5691.333333</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2018</td>\n","      <td>4</td>\n","      <td>05</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>112</td>\n","      <td>4.0</td>\n","      <td>15.276786</td>\n","      <td>134247</td>\n","      <td>2238.776786</td>\n","      <td>112</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   year  month date_of_month  ...  total_duration  mean_distance  num_trips\n","0  2018      4            03  ...             943     419.000000          1\n","1  2018      4            04  ...            4081    5691.333333          3\n","2  2018      4            05  ...          134247    2238.776786        112\n","\n","[3 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":100},"id":"R0kyWhXhu3aj","executionInfo":{"status":"ok","timestamp":1607547002364,"user_tz":360,"elapsed":70109,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"fb62999b-5ca8-441d-fa24-1d460854dd54"},"source":["  month_dict = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May' ,6: 'Jun', 7: 'Jul',8:'Aug' ,9: 'Sept', 10: 'Oct', 11: 'Nov',12: 'Dec'}\n","  weekday_dict = {0: 'Sun', 1: 'Mon', 2: 'Tues', 3: 'Wed', 4: 'Thur', 5:'Fri', 6: 'Sat'}\n","    #Katherine - might be helpful to run a catboost and bring this back in as a categorical variable?\n","  #grouped_data['weekday'] = [weekday_dict[round(day)] for day in grouped_data['weekday']]\n","  grouped_data.head(1)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>date_of_month</th>\n","      <th>num_bicycle</th>\n","      <th>num_moped</th>\n","      <th>num_scooter</th>\n","      <th>weekday</th>\n","      <th>average_trip_hour</th>\n","      <th>total_duration</th>\n","      <th>mean_distance</th>\n","      <th>num_trips</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2018</td>\n","      <td>4</td>\n","      <td>03</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>18.0</td>\n","      <td>943</td>\n","      <td>419.0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   year  month date_of_month  ...  total_duration  mean_distance  num_trips\n","0  2018      4            03  ...             943          419.0          1\n","\n","[1 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"2IAdb99zt6Pd","executionInfo":{"status":"ok","timestamp":1607547002366,"user_tz":360,"elapsed":70105,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}}},"source":[""],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"3w1D2vZseuhl","executionInfo":{"status":"ok","timestamp":1607547002367,"user_tz":360,"elapsed":70096,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}}},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from sklearn.linear_model import LinearRegression\n","\n","train, test = train_test_split(grouped_data, test_size=.30)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"FAULvy3S2a48","executionInfo":{"status":"ok","timestamp":1607547002368,"user_tz":360,"elapsed":70086,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}}},"source":["def reportRegression(target_name, train, test):\n","  if target_name == \"num_trips\":\n","    LR = LinearRegression().fit(train.drop([target_name, \"num_bicycle\", \"num_moped\", \"num_scooter\"], axis=1), train[target_name])\n","    print(\"Predicting for: \" + target_name)\n","    print(\"MSE: \", mean_squared_error(test[target_name], LR.predict(test.drop([target_name, \"num_bicycle\", \"num_moped\", \"num_scooter\"], axis=1))))\n","    print(LR.coef_)\n","  else:\n","    LR = LinearRegression().fit(train.drop([target_name], axis=1), train[target_name])\n","    print(\"Predicting for: \" + target_name)\n","    print(\"MSE: \", mean_squared_error(test[target_name], LR.predict(test.drop([target_name], axis=1))))   "],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"JKwHTlUZeEYK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607547002369,"user_tz":360,"elapsed":70076,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"825b4b5f-d4cd-455b-9c2c-f45a3da6eeec"},"source":["# Target variables - number of trips per day, average trip length, total duration of all trips.\n","for target in [\"num_trips\", \"mean_distance\", \"total_duration\"]:\n","  reportRegression(target, train, test)\n","\n","  #Looks like we can get realistic predictions on number of trips, just have to make sure we cut out num_bicycle/moped/scooter"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Predicting for: num_trips\n","MSE:  6342512.034754368\n","[-4.57336044e+02  1.73380941e+02  5.45329988e+00 -7.79674820e+01\n","  4.45514583e+02  1.26977968e-03 -4.68256904e-04]\n","Predicting for: mean_distance\n","MSE:  24093473896.351818\n","Predicting for: total_duration\n","MSE:  3221695108734.984\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"sT3BhtppNuxX","executionInfo":{"status":"ok","timestamp":1607547002370,"user_tz":360,"elapsed":70060,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"6bee5cd9-25f3-4cd1-f229-57fc27693a8d"},"source":["train.drop([\"num_trips\", \"num_bicycle\", \"num_moped\", \"num_scooter\"], axis=1).head()"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>month</th>\n","      <th>date_of_month</th>\n","      <th>weekday</th>\n","      <th>average_trip_hour</th>\n","      <th>total_duration</th>\n","      <th>mean_distance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>560</th>\n","      <td>2019</td>\n","      <td>11</td>\n","      <td>07</td>\n","      <td>3.989734</td>\n","      <td>13.859992</td>\n","      <td>4565140</td>\n","      <td>39076.406629</td>\n","    </tr>\n","    <tr>\n","      <th>541</th>\n","      <td>2019</td>\n","      <td>10</td>\n","      <td>19</td>\n","      <td>6.000000</td>\n","      <td>15.160983</td>\n","      <td>18526387</td>\n","      <td>171754.195796</td>\n","    </tr>\n","    <tr>\n","      <th>392</th>\n","      <td>2019</td>\n","      <td>5</td>\n","      <td>23</td>\n","      <td>4.000000</td>\n","      <td>15.070471</td>\n","      <td>10517416</td>\n","      <td>1489.115353</td>\n","    </tr>\n","    <tr>\n","      <th>585</th>\n","      <td>2019</td>\n","      <td>12</td>\n","      <td>02</td>\n","      <td>0.978622</td>\n","      <td>14.257210</td>\n","      <td>4219932</td>\n","      <td>26586.637457</td>\n","    </tr>\n","    <tr>\n","      <th>630</th>\n","      <td>2020</td>\n","      <td>1</td>\n","      <td>16</td>\n","      <td>3.974426</td>\n","      <td>13.554246</td>\n","      <td>2927874</td>\n","      <td>6007.456943</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     year  month  ... total_duration  mean_distance\n","560  2019     11  ...        4565140   39076.406629\n","541  2019     10  ...       18526387  171754.195796\n","392  2019      5  ...       10517416    1489.115353\n","585  2019     12  ...        4219932   26586.637457\n","630  2020      1  ...        2927874    6007.456943\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"I9hJ4AX-JW6u","executionInfo":{"status":"ok","timestamp":1607547002370,"user_tz":360,"elapsed":70033,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}}},"source":["#xtrain,xtest,ytrain,ytest = train_test_split(x,y,train_size=0.20,random_state=1236)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"84pDgvhlZVey"},"source":["Catboost\n"]},{"cell_type":"code","metadata":{"id":"95Dq3ZBBeEjd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607547014875,"user_tz":360,"elapsed":82520,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"1f6cd589-8535-4134-ec74-647a449beb7e"},"source":["!pip install catboost\n","from catboost import Pool, CatBoostClassifier, cv, CatBoostRegressor\n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Collecting catboost\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/c1/c1c4707013f9e2f8a96899dd3a87f66c9167d6d776a6dc8fe7ec8678d446/catboost-0.24.3-cp36-none-manylinux1_x86_64.whl (66.3MB)\n","\u001b[K     |████████████████████████████████| 66.3MB 55kB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n","Installing collected packages: catboost\n","Successfully installed catboost-0.24.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7EkwKrZcZSPK","executionInfo":{"status":"ok","timestamp":1607547014876,"user_tz":360,"elapsed":82509,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}}},"source":["model = CatBoostClassifier()"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13JbOCRDGveH","executionInfo":{"status":"ok","timestamp":1607547354615,"user_tz":360,"elapsed":422222,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"a4740b3d-8330-4a48-aa8e-cebf125e0343"},"source":["train, test = train_test_split(merge_data, test_size=.30)\n","#separate data from label\n","x = train.drop('num_trips',axis=1)\n","y = train['num_trips']\n","\n","xtrain,xtest,ytrain,ytest = train_test_split(x,y,train_size=0.20,random_state=1236)\n","model.fit(xtrain,ytrain)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Learning rate set to 0.072947\n","0:\tlearn: 5.2139834\ttotal: 639ms\tremaining: 10m 38s\n","1:\tlearn: 5.1940827\ttotal: 926ms\tremaining: 7m 42s\n","2:\tlearn: 5.1713932\ttotal: 1.25s\tremaining: 6m 54s\n","3:\tlearn: 5.1484389\ttotal: 1.57s\tremaining: 6m 31s\n","4:\tlearn: 5.1257974\ttotal: 1.89s\tremaining: 6m 15s\n","5:\tlearn: 5.1042003\ttotal: 2.23s\tremaining: 6m 9s\n","6:\tlearn: 5.0817824\ttotal: 2.57s\tremaining: 6m 4s\n","7:\tlearn: 5.0627105\ttotal: 2.87s\tremaining: 5m 55s\n","8:\tlearn: 5.0410257\ttotal: 3.17s\tremaining: 5m 48s\n","9:\tlearn: 5.0198118\ttotal: 3.48s\tremaining: 5m 44s\n","10:\tlearn: 4.9987213\ttotal: 3.78s\tremaining: 5m 39s\n","11:\tlearn: 4.9853644\ttotal: 4.06s\tremaining: 5m 34s\n","12:\tlearn: 4.9630922\ttotal: 4.38s\tremaining: 5m 32s\n","13:\tlearn: 4.9409449\ttotal: 4.68s\tremaining: 5m 29s\n","14:\tlearn: 4.9189209\ttotal: 4.98s\tremaining: 5m 26s\n","15:\tlearn: 4.8970885\ttotal: 5.29s\tremaining: 5m 25s\n","16:\tlearn: 4.8792815\ttotal: 5.58s\tremaining: 5m 22s\n","17:\tlearn: 4.8568902\ttotal: 5.88s\tremaining: 5m 20s\n","18:\tlearn: 4.8374006\ttotal: 6.17s\tremaining: 5m 18s\n","19:\tlearn: 4.8148163\ttotal: 6.48s\tremaining: 5m 17s\n","20:\tlearn: 4.7971228\ttotal: 6.76s\tremaining: 5m 15s\n","21:\tlearn: 4.7747845\ttotal: 7.05s\tremaining: 5m 13s\n","22:\tlearn: 4.7547402\ttotal: 7.34s\tremaining: 5m 11s\n","23:\tlearn: 4.7318562\ttotal: 7.75s\tremaining: 5m 15s\n","24:\tlearn: 4.7110300\ttotal: 8.13s\tremaining: 5m 17s\n","25:\tlearn: 4.6886554\ttotal: 8.5s\tremaining: 5m 18s\n","26:\tlearn: 4.6720943\ttotal: 8.79s\tremaining: 5m 16s\n","27:\tlearn: 4.6558190\ttotal: 9.1s\tremaining: 5m 16s\n","28:\tlearn: 4.6361399\ttotal: 9.4s\tremaining: 5m 14s\n","29:\tlearn: 4.6142079\ttotal: 9.8s\tremaining: 5m 16s\n","30:\tlearn: 4.5924275\ttotal: 10.2s\tremaining: 5m 18s\n","31:\tlearn: 4.5701437\ttotal: 10.6s\tremaining: 5m 19s\n","32:\tlearn: 4.5504169\ttotal: 10.9s\tremaining: 5m 18s\n","33:\tlearn: 4.5306746\ttotal: 11.2s\tremaining: 5m 16s\n","34:\tlearn: 4.5099573\ttotal: 11.5s\tremaining: 5m 15s\n","35:\tlearn: 4.4887907\ttotal: 11.9s\tremaining: 5m 17s\n","36:\tlearn: 4.4666791\ttotal: 12.2s\tremaining: 5m 18s\n","37:\tlearn: 4.4459402\ttotal: 12.6s\tremaining: 5m 18s\n","38:\tlearn: 4.4246157\ttotal: 12.9s\tremaining: 5m 17s\n","39:\tlearn: 4.4025773\ttotal: 13.2s\tremaining: 5m 16s\n","40:\tlearn: 4.3817804\ttotal: 13.5s\tremaining: 5m 16s\n","41:\tlearn: 4.3615995\ttotal: 13.9s\tremaining: 5m 17s\n","42:\tlearn: 4.3382858\ttotal: 14.3s\tremaining: 5m 18s\n","43:\tlearn: 4.3167417\ttotal: 14.7s\tremaining: 5m 18s\n","44:\tlearn: 4.2953452\ttotal: 14.9s\tremaining: 5m 17s\n","45:\tlearn: 4.2735223\ttotal: 15.3s\tremaining: 5m 16s\n","46:\tlearn: 4.2546211\ttotal: 15.6s\tremaining: 5m 15s\n","47:\tlearn: 4.2347753\ttotal: 15.8s\tremaining: 5m 14s\n","48:\tlearn: 4.2124455\ttotal: 16.2s\tremaining: 5m 13s\n","49:\tlearn: 4.1915107\ttotal: 16.4s\tremaining: 5m 12s\n","50:\tlearn: 4.1744917\ttotal: 16.7s\tremaining: 5m 11s\n","51:\tlearn: 4.1540499\ttotal: 17s\tremaining: 5m 10s\n","52:\tlearn: 4.1334932\ttotal: 17.3s\tremaining: 5m 9s\n","53:\tlearn: 4.1134969\ttotal: 17.6s\tremaining: 5m 8s\n","54:\tlearn: 4.0914513\ttotal: 17.9s\tremaining: 5m 8s\n","55:\tlearn: 4.0709131\ttotal: 18.2s\tremaining: 5m 7s\n","56:\tlearn: 4.0508565\ttotal: 18.5s\tremaining: 5m 6s\n","57:\tlearn: 4.0283612\ttotal: 18.9s\tremaining: 5m 7s\n","58:\tlearn: 4.0115975\ttotal: 19.3s\tremaining: 5m 7s\n","59:\tlearn: 3.9907163\ttotal: 19.7s\tremaining: 5m 8s\n","60:\tlearn: 3.9694351\ttotal: 20.1s\tremaining: 5m 9s\n","61:\tlearn: 3.9493390\ttotal: 20.5s\tremaining: 5m 9s\n","62:\tlearn: 3.9297117\ttotal: 20.8s\tremaining: 5m 9s\n","63:\tlearn: 3.9129256\ttotal: 21.1s\tremaining: 5m 8s\n","64:\tlearn: 3.8914733\ttotal: 21.4s\tremaining: 5m 8s\n","65:\tlearn: 3.8688311\ttotal: 21.8s\tremaining: 5m 7s\n","66:\tlearn: 3.8482217\ttotal: 22.2s\tremaining: 5m 8s\n","67:\tlearn: 3.8274688\ttotal: 22.6s\tremaining: 5m 9s\n","68:\tlearn: 3.8061550\ttotal: 23s\tremaining: 5m 9s\n","69:\tlearn: 3.7859762\ttotal: 23.4s\tremaining: 5m 10s\n","70:\tlearn: 3.7672035\ttotal: 23.7s\tremaining: 5m 10s\n","71:\tlearn: 3.7463254\ttotal: 24.1s\tremaining: 5m 10s\n","72:\tlearn: 3.7246487\ttotal: 24.9s\tremaining: 5m 16s\n","73:\tlearn: 3.7033450\ttotal: 26.1s\tremaining: 5m 26s\n","74:\tlearn: 3.6824391\ttotal: 26.5s\tremaining: 5m 26s\n","75:\tlearn: 3.6620687\ttotal: 26.9s\tremaining: 5m 27s\n","76:\tlearn: 3.6441631\ttotal: 27.3s\tremaining: 5m 27s\n","77:\tlearn: 3.6232216\ttotal: 27.7s\tremaining: 5m 27s\n","78:\tlearn: 3.6009601\ttotal: 28s\tremaining: 5m 26s\n","79:\tlearn: 3.5819249\ttotal: 28.3s\tremaining: 5m 25s\n","80:\tlearn: 3.5601270\ttotal: 28.6s\tremaining: 5m 24s\n","81:\tlearn: 3.5416550\ttotal: 28.9s\tremaining: 5m 23s\n","82:\tlearn: 3.5207143\ttotal: 29.2s\tremaining: 5m 22s\n","83:\tlearn: 3.5001732\ttotal: 29.5s\tremaining: 5m 21s\n","84:\tlearn: 3.4836823\ttotal: 29.8s\tremaining: 5m 20s\n","85:\tlearn: 3.4637499\ttotal: 30.2s\tremaining: 5m 21s\n","86:\tlearn: 3.4437529\ttotal: 30.6s\tremaining: 5m 21s\n","87:\tlearn: 3.4240049\ttotal: 31s\tremaining: 5m 21s\n","88:\tlearn: 3.4049242\ttotal: 31.3s\tremaining: 5m 20s\n","89:\tlearn: 3.3853223\ttotal: 31.7s\tremaining: 5m 20s\n","90:\tlearn: 3.3666758\ttotal: 32s\tremaining: 5m 19s\n","91:\tlearn: 3.3492915\ttotal: 32.4s\tremaining: 5m 19s\n","92:\tlearn: 3.3287204\ttotal: 32.8s\tremaining: 5m 20s\n","93:\tlearn: 3.3105649\ttotal: 33.2s\tremaining: 5m 19s\n","94:\tlearn: 3.2950108\ttotal: 33.5s\tremaining: 5m 18s\n","95:\tlearn: 3.2802414\ttotal: 33.8s\tremaining: 5m 18s\n","96:\tlearn: 3.2607097\ttotal: 34.1s\tremaining: 5m 17s\n","97:\tlearn: 3.2420258\ttotal: 34.5s\tremaining: 5m 17s\n","98:\tlearn: 3.2241324\ttotal: 34.9s\tremaining: 5m 17s\n","99:\tlearn: 3.2050873\ttotal: 35.3s\tremaining: 5m 17s\n","100:\tlearn: 3.1905664\ttotal: 35.7s\tremaining: 5m 17s\n","101:\tlearn: 3.1709238\ttotal: 36.1s\tremaining: 5m 17s\n","102:\tlearn: 3.1566482\ttotal: 36.5s\tremaining: 5m 17s\n","103:\tlearn: 3.1369695\ttotal: 36.9s\tremaining: 5m 17s\n","104:\tlearn: 3.1214441\ttotal: 37.3s\tremaining: 5m 17s\n","105:\tlearn: 3.1060690\ttotal: 37.6s\tremaining: 5m 17s\n","106:\tlearn: 3.1035918\ttotal: 38s\tremaining: 5m 17s\n","107:\tlearn: 3.0872767\ttotal: 38.3s\tremaining: 5m 16s\n","108:\tlearn: 3.0685940\ttotal: 38.6s\tremaining: 5m 15s\n","109:\tlearn: 3.0514320\ttotal: 38.9s\tremaining: 5m 14s\n","110:\tlearn: 3.0354712\ttotal: 39.2s\tremaining: 5m 13s\n","111:\tlearn: 3.0255822\ttotal: 39.4s\tremaining: 5m 12s\n","112:\tlearn: 3.0154516\ttotal: 39.7s\tremaining: 5m 11s\n","113:\tlearn: 3.0024218\ttotal: 40s\tremaining: 5m 11s\n","114:\tlearn: 2.9876107\ttotal: 40.3s\tremaining: 5m 10s\n","115:\tlearn: 2.9801940\ttotal: 40.6s\tremaining: 5m 9s\n","116:\tlearn: 2.9718720\ttotal: 40.9s\tremaining: 5m 8s\n","117:\tlearn: 2.9538603\ttotal: 41.2s\tremaining: 5m 7s\n","118:\tlearn: 2.9406702\ttotal: 41.5s\tremaining: 5m 7s\n","119:\tlearn: 2.9214447\ttotal: 41.8s\tremaining: 5m 6s\n","120:\tlearn: 2.9047831\ttotal: 42.1s\tremaining: 5m 5s\n","121:\tlearn: 2.8978974\ttotal: 42.3s\tremaining: 5m 4s\n","122:\tlearn: 2.8812733\ttotal: 42.6s\tremaining: 5m 4s\n","123:\tlearn: 2.8657968\ttotal: 42.9s\tremaining: 5m 3s\n","124:\tlearn: 2.8507801\ttotal: 43.2s\tremaining: 5m 2s\n","125:\tlearn: 2.8431949\ttotal: 43.5s\tremaining: 5m 1s\n","126:\tlearn: 2.8309632\ttotal: 43.8s\tremaining: 5m\n","127:\tlearn: 2.8167411\ttotal: 44s\tremaining: 5m\n","128:\tlearn: 2.8010628\ttotal: 44.3s\tremaining: 4m 59s\n","129:\tlearn: 2.7848049\ttotal: 44.6s\tremaining: 4m 58s\n","130:\tlearn: 2.7667483\ttotal: 44.9s\tremaining: 4m 58s\n","131:\tlearn: 2.7567158\ttotal: 45.2s\tremaining: 4m 57s\n","132:\tlearn: 2.7465618\ttotal: 45.6s\tremaining: 4m 57s\n","133:\tlearn: 2.7354108\ttotal: 46s\tremaining: 4m 56s\n","134:\tlearn: 2.7186667\ttotal: 46.3s\tremaining: 4m 56s\n","135:\tlearn: 2.6998004\ttotal: 46.7s\tremaining: 4m 56s\n","136:\tlearn: 2.6816273\ttotal: 47.1s\tremaining: 4m 56s\n","137:\tlearn: 2.6751260\ttotal: 47.4s\tremaining: 4m 56s\n","138:\tlearn: 2.6615483\ttotal: 47.7s\tremaining: 4m 55s\n","139:\tlearn: 2.6459356\ttotal: 48s\tremaining: 4m 54s\n","140:\tlearn: 2.6363419\ttotal: 48.3s\tremaining: 4m 54s\n","141:\tlearn: 2.6214333\ttotal: 48.7s\tremaining: 4m 54s\n","142:\tlearn: 2.6060478\ttotal: 49s\tremaining: 4m 53s\n","143:\tlearn: 2.5898676\ttotal: 49.4s\tremaining: 4m 53s\n","144:\tlearn: 2.5795694\ttotal: 49.8s\tremaining: 4m 53s\n","145:\tlearn: 2.5640402\ttotal: 50.2s\tremaining: 4m 53s\n","146:\tlearn: 2.5525191\ttotal: 50.6s\tremaining: 4m 53s\n","147:\tlearn: 2.5390094\ttotal: 51s\tremaining: 4m 53s\n","148:\tlearn: 2.5228009\ttotal: 51.4s\tremaining: 4m 53s\n","149:\tlearn: 2.5114430\ttotal: 51.6s\tremaining: 4m 52s\n","150:\tlearn: 2.4987655\ttotal: 51.9s\tremaining: 4m 51s\n","151:\tlearn: 2.4863120\ttotal: 52.2s\tremaining: 4m 51s\n","152:\tlearn: 2.4703231\ttotal: 52.5s\tremaining: 4m 50s\n","153:\tlearn: 2.4591804\ttotal: 52.8s\tremaining: 4m 50s\n","154:\tlearn: 2.4481560\ttotal: 53.1s\tremaining: 4m 49s\n","155:\tlearn: 2.4418462\ttotal: 53.4s\tremaining: 4m 48s\n","156:\tlearn: 2.4259564\ttotal: 53.7s\tremaining: 4m 48s\n","157:\tlearn: 2.4168181\ttotal: 54s\tremaining: 4m 47s\n","158:\tlearn: 2.4028689\ttotal: 54.2s\tremaining: 4m 46s\n","159:\tlearn: 2.3885555\ttotal: 54.5s\tremaining: 4m 46s\n","160:\tlearn: 2.3766423\ttotal: 54.8s\tremaining: 4m 45s\n","161:\tlearn: 2.3630734\ttotal: 55.1s\tremaining: 4m 45s\n","162:\tlearn: 2.3527126\ttotal: 55.4s\tremaining: 4m 44s\n","163:\tlearn: 2.3363109\ttotal: 55.8s\tremaining: 4m 44s\n","164:\tlearn: 2.3224765\ttotal: 56.2s\tremaining: 4m 44s\n","165:\tlearn: 2.3063051\ttotal: 56.6s\tremaining: 4m 44s\n","166:\tlearn: 2.2913818\ttotal: 57s\tremaining: 4m 44s\n","167:\tlearn: 2.2802489\ttotal: 57.4s\tremaining: 4m 44s\n","168:\tlearn: 2.2685570\ttotal: 57.8s\tremaining: 4m 44s\n","169:\tlearn: 2.2547123\ttotal: 58.2s\tremaining: 4m 44s\n","170:\tlearn: 2.2501619\ttotal: 58.6s\tremaining: 4m 43s\n","171:\tlearn: 2.2390803\ttotal: 58.9s\tremaining: 4m 43s\n","172:\tlearn: 2.2245366\ttotal: 59.3s\tremaining: 4m 43s\n","173:\tlearn: 2.2106228\ttotal: 59.7s\tremaining: 4m 43s\n","174:\tlearn: 2.1954335\ttotal: 1m\tremaining: 4m 43s\n","175:\tlearn: 2.1842254\ttotal: 1m\tremaining: 4m 43s\n","176:\tlearn: 2.1701072\ttotal: 1m\tremaining: 4m 43s\n","177:\tlearn: 2.1590452\ttotal: 1m 1s\tremaining: 4m 42s\n","178:\tlearn: 2.1482097\ttotal: 1m 1s\tremaining: 4m 42s\n","179:\tlearn: 2.1466174\ttotal: 1m 1s\tremaining: 4m 41s\n","180:\tlearn: 2.1381326\ttotal: 1m 2s\tremaining: 4m 41s\n","181:\tlearn: 2.1263945\ttotal: 1m 2s\tremaining: 4m 40s\n","182:\tlearn: 2.1166269\ttotal: 1m 2s\tremaining: 4m 40s\n","183:\tlearn: 2.1028689\ttotal: 1m 3s\tremaining: 4m 39s\n","184:\tlearn: 2.0907405\ttotal: 1m 3s\tremaining: 4m 38s\n","185:\tlearn: 2.0819476\ttotal: 1m 3s\tremaining: 4m 38s\n","186:\tlearn: 2.0689056\ttotal: 1m 3s\tremaining: 4m 37s\n","187:\tlearn: 2.0582952\ttotal: 1m 4s\tremaining: 4m 37s\n","188:\tlearn: 2.0431364\ttotal: 1m 4s\tremaining: 4m 36s\n","189:\tlearn: 2.0320805\ttotal: 1m 4s\tremaining: 4m 36s\n","190:\tlearn: 2.0201168\ttotal: 1m 5s\tremaining: 4m 35s\n","191:\tlearn: 2.0134145\ttotal: 1m 5s\tremaining: 4m 35s\n","192:\tlearn: 1.9995167\ttotal: 1m 5s\tremaining: 4m 34s\n","193:\tlearn: 1.9852388\ttotal: 1m 5s\tremaining: 4m 34s\n","194:\tlearn: 1.9714408\ttotal: 1m 6s\tremaining: 4m 33s\n","195:\tlearn: 1.9582049\ttotal: 1m 6s\tremaining: 4m 33s\n","196:\tlearn: 1.9493610\ttotal: 1m 6s\tremaining: 4m 32s\n","197:\tlearn: 1.9423939\ttotal: 1m 7s\tremaining: 4m 32s\n","198:\tlearn: 1.9342716\ttotal: 1m 7s\tremaining: 4m 32s\n","199:\tlearn: 1.9200722\ttotal: 1m 7s\tremaining: 4m 31s\n","200:\tlearn: 1.9099519\ttotal: 1m 8s\tremaining: 4m 31s\n","201:\tlearn: 1.8983430\ttotal: 1m 8s\tremaining: 4m 30s\n","202:\tlearn: 1.8856046\ttotal: 1m 8s\tremaining: 4m 30s\n","203:\tlearn: 1.8715769\ttotal: 1m 9s\tremaining: 4m 30s\n","204:\tlearn: 1.8632638\ttotal: 1m 9s\tremaining: 4m 30s\n","205:\tlearn: 1.8534034\ttotal: 1m 10s\tremaining: 4m 30s\n","206:\tlearn: 1.8444909\ttotal: 1m 10s\tremaining: 4m 29s\n","207:\tlearn: 1.8326499\ttotal: 1m 10s\tremaining: 4m 29s\n","208:\tlearn: 1.8262922\ttotal: 1m 11s\tremaining: 4m 29s\n","209:\tlearn: 1.8125352\ttotal: 1m 11s\tremaining: 4m 29s\n","210:\tlearn: 1.8048657\ttotal: 1m 11s\tremaining: 4m 28s\n","211:\tlearn: 1.7941257\ttotal: 1m 12s\tremaining: 4m 28s\n","212:\tlearn: 1.7814094\ttotal: 1m 12s\tremaining: 4m 27s\n","213:\tlearn: 1.7753963\ttotal: 1m 12s\tremaining: 4m 27s\n","214:\tlearn: 1.7625400\ttotal: 1m 13s\tremaining: 4m 26s\n","215:\tlearn: 1.7508578\ttotal: 1m 13s\tremaining: 4m 26s\n","216:\tlearn: 1.7397108\ttotal: 1m 13s\tremaining: 4m 25s\n","217:\tlearn: 1.7285350\ttotal: 1m 14s\tremaining: 4m 25s\n","218:\tlearn: 1.7180876\ttotal: 1m 14s\tremaining: 4m 25s\n","219:\tlearn: 1.7075555\ttotal: 1m 14s\tremaining: 4m 25s\n","220:\tlearn: 1.6952714\ttotal: 1m 15s\tremaining: 4m 25s\n","221:\tlearn: 1.6833789\ttotal: 1m 15s\tremaining: 4m 24s\n","222:\tlearn: 1.6753696\ttotal: 1m 15s\tremaining: 4m 24s\n","223:\tlearn: 1.6648687\ttotal: 1m 16s\tremaining: 4m 24s\n","224:\tlearn: 1.6544936\ttotal: 1m 16s\tremaining: 4m 23s\n","225:\tlearn: 1.6510187\ttotal: 1m 16s\tremaining: 4m 22s\n","226:\tlearn: 1.6395012\ttotal: 1m 17s\tremaining: 4m 22s\n","227:\tlearn: 1.6295772\ttotal: 1m 17s\tremaining: 4m 21s\n","228:\tlearn: 1.6245411\ttotal: 1m 17s\tremaining: 4m 21s\n","229:\tlearn: 1.6134884\ttotal: 1m 17s\tremaining: 4m 20s\n","230:\tlearn: 1.6057703\ttotal: 1m 18s\tremaining: 4m 20s\n","231:\tlearn: 1.6014979\ttotal: 1m 18s\tremaining: 4m 19s\n","232:\tlearn: 1.5900942\ttotal: 1m 18s\tremaining: 4m 19s\n","233:\tlearn: 1.5787208\ttotal: 1m 19s\tremaining: 4m 18s\n","234:\tlearn: 1.5691119\ttotal: 1m 19s\tremaining: 4m 18s\n","235:\tlearn: 1.5601745\ttotal: 1m 19s\tremaining: 4m 17s\n","236:\tlearn: 1.5495589\ttotal: 1m 19s\tremaining: 4m 17s\n","237:\tlearn: 1.5384777\ttotal: 1m 20s\tremaining: 4m 17s\n","238:\tlearn: 1.5306811\ttotal: 1m 20s\tremaining: 4m 16s\n","239:\tlearn: 1.5233022\ttotal: 1m 20s\tremaining: 4m 16s\n","240:\tlearn: 1.5162499\ttotal: 1m 21s\tremaining: 4m 15s\n","241:\tlearn: 1.5053373\ttotal: 1m 21s\tremaining: 4m 15s\n","242:\tlearn: 1.4949015\ttotal: 1m 22s\tremaining: 4m 15s\n","243:\tlearn: 1.4837432\ttotal: 1m 22s\tremaining: 4m 15s\n","244:\tlearn: 1.4761769\ttotal: 1m 22s\tremaining: 4m 14s\n","245:\tlearn: 1.4732965\ttotal: 1m 22s\tremaining: 4m 13s\n","246:\tlearn: 1.4648503\ttotal: 1m 23s\tremaining: 4m 13s\n","247:\tlearn: 1.4552774\ttotal: 1m 23s\tremaining: 4m 13s\n","248:\tlearn: 1.4491299\ttotal: 1m 23s\tremaining: 4m 12s\n","249:\tlearn: 1.4429294\ttotal: 1m 24s\tremaining: 4m 12s\n","250:\tlearn: 1.4329502\ttotal: 1m 24s\tremaining: 4m 11s\n","251:\tlearn: 1.4221747\ttotal: 1m 24s\tremaining: 4m 11s\n","252:\tlearn: 1.4172708\ttotal: 1m 25s\tremaining: 4m 11s\n","253:\tlearn: 1.4089407\ttotal: 1m 25s\tremaining: 4m 10s\n","254:\tlearn: 1.4015416\ttotal: 1m 25s\tremaining: 4m 10s\n","255:\tlearn: 1.3914360\ttotal: 1m 25s\tremaining: 4m 9s\n","256:\tlearn: 1.3828400\ttotal: 1m 26s\tremaining: 4m 9s\n","257:\tlearn: 1.3803345\ttotal: 1m 26s\tremaining: 4m 8s\n","258:\tlearn: 1.3733556\ttotal: 1m 26s\tremaining: 4m 8s\n","259:\tlearn: 1.3646437\ttotal: 1m 27s\tremaining: 4m 8s\n","260:\tlearn: 1.3555121\ttotal: 1m 27s\tremaining: 4m 7s\n","261:\tlearn: 1.3477970\ttotal: 1m 27s\tremaining: 4m 7s\n","262:\tlearn: 1.3396171\ttotal: 1m 28s\tremaining: 4m 7s\n","263:\tlearn: 1.3332560\ttotal: 1m 28s\tremaining: 4m 6s\n","264:\tlearn: 1.3245927\ttotal: 1m 28s\tremaining: 4m 6s\n","265:\tlearn: 1.3192188\ttotal: 1m 29s\tremaining: 4m 5s\n","266:\tlearn: 1.3127636\ttotal: 1m 29s\tremaining: 4m 5s\n","267:\tlearn: 1.3039278\ttotal: 1m 29s\tremaining: 4m 5s\n","268:\tlearn: 1.2973580\ttotal: 1m 30s\tremaining: 4m 5s\n","269:\tlearn: 1.2891086\ttotal: 1m 30s\tremaining: 4m 4s\n","270:\tlearn: 1.2827390\ttotal: 1m 30s\tremaining: 4m 4s\n","271:\tlearn: 1.2753695\ttotal: 1m 31s\tremaining: 4m 4s\n","272:\tlearn: 1.2666917\ttotal: 1m 31s\tremaining: 4m 4s\n","273:\tlearn: 1.2607432\ttotal: 1m 32s\tremaining: 4m 4s\n","274:\tlearn: 1.2524708\ttotal: 1m 32s\tremaining: 4m 3s\n","275:\tlearn: 1.2431407\ttotal: 1m 32s\tremaining: 4m 3s\n","276:\tlearn: 1.2383537\ttotal: 1m 32s\tremaining: 4m 2s\n","277:\tlearn: 1.2332005\ttotal: 1m 33s\tremaining: 4m 2s\n","278:\tlearn: 1.2254587\ttotal: 1m 33s\tremaining: 4m 2s\n","279:\tlearn: 1.2222784\ttotal: 1m 34s\tremaining: 4m 1s\n","280:\tlearn: 1.2159187\ttotal: 1m 34s\tremaining: 4m 1s\n","281:\tlearn: 1.2118055\ttotal: 1m 34s\tremaining: 4m 1s\n","282:\tlearn: 1.2073382\ttotal: 1m 35s\tremaining: 4m 1s\n","283:\tlearn: 1.1990170\ttotal: 1m 35s\tremaining: 4m\n","284:\tlearn: 1.1911372\ttotal: 1m 35s\tremaining: 4m\n","285:\tlearn: 1.1833889\ttotal: 1m 36s\tremaining: 4m\n","286:\tlearn: 1.1756763\ttotal: 1m 36s\tremaining: 3m 59s\n","287:\tlearn: 1.1700145\ttotal: 1m 36s\tremaining: 3m 59s\n","288:\tlearn: 1.1612975\ttotal: 1m 37s\tremaining: 3m 59s\n","289:\tlearn: 1.1528507\ttotal: 1m 37s\tremaining: 3m 58s\n","290:\tlearn: 1.1441373\ttotal: 1m 37s\tremaining: 3m 58s\n","291:\tlearn: 1.1360241\ttotal: 1m 38s\tremaining: 3m 58s\n","292:\tlearn: 1.1313860\ttotal: 1m 38s\tremaining: 3m 58s\n","293:\tlearn: 1.1253979\ttotal: 1m 39s\tremaining: 3m 57s\n","294:\tlearn: 1.1187052\ttotal: 1m 39s\tremaining: 3m 57s\n","295:\tlearn: 1.1107041\ttotal: 1m 39s\tremaining: 3m 57s\n","296:\tlearn: 1.1017800\ttotal: 1m 39s\tremaining: 3m 56s\n","297:\tlearn: 1.0933002\ttotal: 1m 40s\tremaining: 3m 56s\n","298:\tlearn: 1.0856758\ttotal: 1m 40s\tremaining: 3m 56s\n","299:\tlearn: 1.0801968\ttotal: 1m 41s\tremaining: 3m 55s\n","300:\tlearn: 1.0726073\ttotal: 1m 41s\tremaining: 3m 55s\n","301:\tlearn: 1.0649977\ttotal: 1m 41s\tremaining: 3m 55s\n","302:\tlearn: 1.0565587\ttotal: 1m 42s\tremaining: 3m 54s\n","303:\tlearn: 1.0507098\ttotal: 1m 42s\tremaining: 3m 54s\n","304:\tlearn: 1.0424030\ttotal: 1m 42s\tremaining: 3m 53s\n","305:\tlearn: 1.0353992\ttotal: 1m 42s\tremaining: 3m 53s\n","306:\tlearn: 1.0286054\ttotal: 1m 43s\tremaining: 3m 53s\n","307:\tlearn: 1.0212156\ttotal: 1m 43s\tremaining: 3m 52s\n","308:\tlearn: 1.0149910\ttotal: 1m 43s\tremaining: 3m 52s\n","309:\tlearn: 1.0078145\ttotal: 1m 44s\tremaining: 3m 51s\n","310:\tlearn: 1.0030413\ttotal: 1m 44s\tremaining: 3m 51s\n","311:\tlearn: 0.9958973\ttotal: 1m 44s\tremaining: 3m 50s\n","312:\tlearn: 0.9909145\ttotal: 1m 44s\tremaining: 3m 50s\n","313:\tlearn: 0.9844556\ttotal: 1m 45s\tremaining: 3m 49s\n","314:\tlearn: 0.9772602\ttotal: 1m 45s\tremaining: 3m 49s\n","315:\tlearn: 0.9722318\ttotal: 1m 45s\tremaining: 3m 49s\n","316:\tlearn: 0.9673349\ttotal: 1m 46s\tremaining: 3m 49s\n","317:\tlearn: 0.9652104\ttotal: 1m 46s\tremaining: 3m 48s\n","318:\tlearn: 0.9579511\ttotal: 1m 46s\tremaining: 3m 48s\n","319:\tlearn: 0.9511761\ttotal: 1m 47s\tremaining: 3m 47s\n","320:\tlearn: 0.9475409\ttotal: 1m 47s\tremaining: 3m 47s\n","321:\tlearn: 0.9405550\ttotal: 1m 47s\tremaining: 3m 47s\n","322:\tlearn: 0.9347766\ttotal: 1m 48s\tremaining: 3m 46s\n","323:\tlearn: 0.9307748\ttotal: 1m 48s\tremaining: 3m 46s\n","324:\tlearn: 0.9266644\ttotal: 1m 48s\tremaining: 3m 45s\n","325:\tlearn: 0.9224927\ttotal: 1m 49s\tremaining: 3m 45s\n","326:\tlearn: 0.9157361\ttotal: 1m 49s\tremaining: 3m 45s\n","327:\tlearn: 0.9114565\ttotal: 1m 49s\tremaining: 3m 44s\n","328:\tlearn: 0.9048355\ttotal: 1m 50s\tremaining: 3m 44s\n","329:\tlearn: 0.9005197\ttotal: 1m 50s\tremaining: 3m 44s\n","330:\tlearn: 0.8942577\ttotal: 1m 50s\tremaining: 3m 43s\n","331:\tlearn: 0.8899317\ttotal: 1m 51s\tremaining: 3m 43s\n","332:\tlearn: 0.8856235\ttotal: 1m 51s\tremaining: 3m 43s\n","333:\tlearn: 0.8792813\ttotal: 1m 51s\tremaining: 3m 43s\n","334:\tlearn: 0.8731996\ttotal: 1m 52s\tremaining: 3m 42s\n","335:\tlearn: 0.8672274\ttotal: 1m 52s\tremaining: 3m 42s\n","336:\tlearn: 0.8624191\ttotal: 1m 53s\tremaining: 3m 42s\n","337:\tlearn: 0.8569865\ttotal: 1m 53s\tremaining: 3m 42s\n","338:\tlearn: 0.8519857\ttotal: 1m 53s\tremaining: 3m 41s\n","339:\tlearn: 0.8482666\ttotal: 1m 54s\tremaining: 3m 41s\n","340:\tlearn: 0.8423328\ttotal: 1m 54s\tremaining: 3m 40s\n","341:\tlearn: 0.8376423\ttotal: 1m 54s\tremaining: 3m 40s\n","342:\tlearn: 0.8340647\ttotal: 1m 54s\tremaining: 3m 40s\n","343:\tlearn: 0.8284091\ttotal: 1m 55s\tremaining: 3m 39s\n","344:\tlearn: 0.8234185\ttotal: 1m 55s\tremaining: 3m 39s\n","345:\tlearn: 0.8176325\ttotal: 1m 56s\tremaining: 3m 39s\n","346:\tlearn: 0.8128429\ttotal: 1m 56s\tremaining: 3m 39s\n","347:\tlearn: 0.8071311\ttotal: 1m 56s\tremaining: 3m 38s\n","348:\tlearn: 0.8045329\ttotal: 1m 57s\tremaining: 3m 38s\n","349:\tlearn: 0.8005541\ttotal: 1m 57s\tremaining: 3m 38s\n","350:\tlearn: 0.7957140\ttotal: 1m 57s\tremaining: 3m 38s\n","351:\tlearn: 0.7915680\ttotal: 1m 58s\tremaining: 3m 37s\n","352:\tlearn: 0.7867256\ttotal: 1m 58s\tremaining: 3m 37s\n","353:\tlearn: 0.7834672\ttotal: 1m 58s\tremaining: 3m 37s\n","354:\tlearn: 0.7803387\ttotal: 1m 59s\tremaining: 3m 36s\n","355:\tlearn: 0.7791416\ttotal: 1m 59s\tremaining: 3m 36s\n","356:\tlearn: 0.7738546\ttotal: 1m 59s\tremaining: 3m 35s\n","357:\tlearn: 0.7723540\ttotal: 2m\tremaining: 3m 35s\n","358:\tlearn: 0.7674339\ttotal: 2m\tremaining: 3m 35s\n","359:\tlearn: 0.7643665\ttotal: 2m\tremaining: 3m 34s\n","360:\tlearn: 0.7590831\ttotal: 2m 1s\tremaining: 3m 34s\n","361:\tlearn: 0.7584601\ttotal: 2m 1s\tremaining: 3m 33s\n","362:\tlearn: 0.7540900\ttotal: 2m 1s\tremaining: 3m 33s\n","363:\tlearn: 0.7495381\ttotal: 2m 1s\tremaining: 3m 32s\n","364:\tlearn: 0.7445004\ttotal: 2m 2s\tremaining: 3m 32s\n","365:\tlearn: 0.7395555\ttotal: 2m 2s\tremaining: 3m 32s\n","366:\tlearn: 0.7351592\ttotal: 2m 3s\tremaining: 3m 32s\n","367:\tlearn: 0.7303710\ttotal: 2m 3s\tremaining: 3m 31s\n","368:\tlearn: 0.7250461\ttotal: 2m 3s\tremaining: 3m 31s\n","369:\tlearn: 0.7204624\ttotal: 2m 3s\tremaining: 3m 31s\n","370:\tlearn: 0.7181262\ttotal: 2m 4s\tremaining: 3m 30s\n","371:\tlearn: 0.7139502\ttotal: 2m 4s\tremaining: 3m 30s\n","372:\tlearn: 0.7097090\ttotal: 2m 4s\tremaining: 3m 29s\n","373:\tlearn: 0.7050519\ttotal: 2m 5s\tremaining: 3m 29s\n","374:\tlearn: 0.7007987\ttotal: 2m 5s\tremaining: 3m 29s\n","375:\tlearn: 0.6965648\ttotal: 2m 5s\tremaining: 3m 28s\n","376:\tlearn: 0.6927774\ttotal: 2m 6s\tremaining: 3m 28s\n","377:\tlearn: 0.6888383\ttotal: 2m 6s\tremaining: 3m 28s\n","378:\tlearn: 0.6860559\ttotal: 2m 6s\tremaining: 3m 27s\n","379:\tlearn: 0.6820238\ttotal: 2m 7s\tremaining: 3m 27s\n","380:\tlearn: 0.6780035\ttotal: 2m 7s\tremaining: 3m 27s\n","381:\tlearn: 0.6741911\ttotal: 2m 7s\tremaining: 3m 27s\n","382:\tlearn: 0.6709769\ttotal: 2m 8s\tremaining: 3m 26s\n","383:\tlearn: 0.6667513\ttotal: 2m 8s\tremaining: 3m 26s\n","384:\tlearn: 0.6627351\ttotal: 2m 9s\tremaining: 3m 26s\n","385:\tlearn: 0.6587778\ttotal: 2m 9s\tremaining: 3m 25s\n","386:\tlearn: 0.6561942\ttotal: 2m 9s\tremaining: 3m 25s\n","387:\tlearn: 0.6524983\ttotal: 2m 10s\tremaining: 3m 25s\n","388:\tlearn: 0.6483066\ttotal: 2m 10s\tremaining: 3m 25s\n","389:\tlearn: 0.6454375\ttotal: 2m 10s\tremaining: 3m 24s\n","390:\tlearn: 0.6415805\ttotal: 2m 11s\tremaining: 3m 24s\n","391:\tlearn: 0.6373635\ttotal: 2m 11s\tremaining: 3m 24s\n","392:\tlearn: 0.6342537\ttotal: 2m 12s\tremaining: 3m 24s\n","393:\tlearn: 0.6301901\ttotal: 2m 12s\tremaining: 3m 23s\n","394:\tlearn: 0.6268885\ttotal: 2m 12s\tremaining: 3m 23s\n","395:\tlearn: 0.6241218\ttotal: 2m 13s\tremaining: 3m 23s\n","396:\tlearn: 0.6216357\ttotal: 2m 13s\tremaining: 3m 22s\n","397:\tlearn: 0.6185270\ttotal: 2m 13s\tremaining: 3m 22s\n","398:\tlearn: 0.6155884\ttotal: 2m 14s\tremaining: 3m 22s\n","399:\tlearn: 0.6123810\ttotal: 2m 14s\tremaining: 3m 21s\n","400:\tlearn: 0.6104322\ttotal: 2m 14s\tremaining: 3m 21s\n","401:\tlearn: 0.6066758\ttotal: 2m 15s\tremaining: 3m 21s\n","402:\tlearn: 0.6035411\ttotal: 2m 15s\tremaining: 3m 20s\n","403:\tlearn: 0.5996055\ttotal: 2m 15s\tremaining: 3m 20s\n","404:\tlearn: 0.5972218\ttotal: 2m 16s\tremaining: 3m 20s\n","405:\tlearn: 0.5941902\ttotal: 2m 16s\tremaining: 3m 19s\n","406:\tlearn: 0.5912494\ttotal: 2m 16s\tremaining: 3m 19s\n","407:\tlearn: 0.5887917\ttotal: 2m 16s\tremaining: 3m 18s\n","408:\tlearn: 0.5855945\ttotal: 2m 17s\tremaining: 3m 18s\n","409:\tlearn: 0.5823694\ttotal: 2m 17s\tremaining: 3m 18s\n","410:\tlearn: 0.5789032\ttotal: 2m 18s\tremaining: 3m 17s\n","411:\tlearn: 0.5764504\ttotal: 2m 18s\tremaining: 3m 17s\n","412:\tlearn: 0.5734678\ttotal: 2m 18s\tremaining: 3m 17s\n","413:\tlearn: 0.5701274\ttotal: 2m 19s\tremaining: 3m 17s\n","414:\tlearn: 0.5677295\ttotal: 2m 19s\tremaining: 3m 16s\n","415:\tlearn: 0.5644672\ttotal: 2m 19s\tremaining: 3m 16s\n","416:\tlearn: 0.5612717\ttotal: 2m 20s\tremaining: 3m 16s\n","417:\tlearn: 0.5585927\ttotal: 2m 20s\tremaining: 3m 15s\n","418:\tlearn: 0.5560389\ttotal: 2m 20s\tremaining: 3m 15s\n","419:\tlearn: 0.5535035\ttotal: 2m 21s\tremaining: 3m 14s\n","420:\tlearn: 0.5514871\ttotal: 2m 21s\tremaining: 3m 14s\n","421:\tlearn: 0.5486765\ttotal: 2m 21s\tremaining: 3m 14s\n","422:\tlearn: 0.5455587\ttotal: 2m 22s\tremaining: 3m 13s\n","423:\tlearn: 0.5421999\ttotal: 2m 22s\tremaining: 3m 13s\n","424:\tlearn: 0.5399950\ttotal: 2m 22s\tremaining: 3m 13s\n","425:\tlearn: 0.5372019\ttotal: 2m 23s\tremaining: 3m 12s\n","426:\tlearn: 0.5356893\ttotal: 2m 23s\tremaining: 3m 12s\n","427:\tlearn: 0.5331743\ttotal: 2m 23s\tremaining: 3m 12s\n","428:\tlearn: 0.5299877\ttotal: 2m 24s\tremaining: 3m 12s\n","429:\tlearn: 0.5270725\ttotal: 2m 24s\tremaining: 3m 11s\n","430:\tlearn: 0.5240633\ttotal: 2m 24s\tremaining: 3m 11s\n","431:\tlearn: 0.5211342\ttotal: 2m 25s\tremaining: 3m 10s\n","432:\tlearn: 0.5185365\ttotal: 2m 25s\tremaining: 3m 10s\n","433:\tlearn: 0.5163934\ttotal: 2m 25s\tremaining: 3m 10s\n","434:\tlearn: 0.5141149\ttotal: 2m 26s\tremaining: 3m 9s\n","435:\tlearn: 0.5113610\ttotal: 2m 26s\tremaining: 3m 9s\n","436:\tlearn: 0.5086756\ttotal: 2m 26s\tremaining: 3m 9s\n","437:\tlearn: 0.5061577\ttotal: 2m 27s\tremaining: 3m 8s\n","438:\tlearn: 0.5036546\ttotal: 2m 27s\tremaining: 3m 8s\n","439:\tlearn: 0.5010029\ttotal: 2m 27s\tremaining: 3m 8s\n","440:\tlearn: 0.4985542\ttotal: 2m 28s\tremaining: 3m 7s\n","441:\tlearn: 0.4977803\ttotal: 2m 28s\tremaining: 3m 7s\n","442:\tlearn: 0.4958304\ttotal: 2m 28s\tremaining: 3m 6s\n","443:\tlearn: 0.4936663\ttotal: 2m 28s\tremaining: 3m 6s\n","444:\tlearn: 0.4910697\ttotal: 2m 29s\tremaining: 3m 6s\n","445:\tlearn: 0.4883960\ttotal: 2m 29s\tremaining: 3m 5s\n","446:\tlearn: 0.4857191\ttotal: 2m 29s\tremaining: 3m 5s\n","447:\tlearn: 0.4836360\ttotal: 2m 30s\tremaining: 3m 5s\n","448:\tlearn: 0.4813611\ttotal: 2m 30s\tremaining: 3m 4s\n","449:\tlearn: 0.4789472\ttotal: 2m 30s\tremaining: 3m 4s\n","450:\tlearn: 0.4770134\ttotal: 2m 31s\tremaining: 3m 4s\n","451:\tlearn: 0.4750873\ttotal: 2m 31s\tremaining: 3m 3s\n","452:\tlearn: 0.4727778\ttotal: 2m 31s\tremaining: 3m 3s\n","453:\tlearn: 0.4707970\ttotal: 2m 32s\tremaining: 3m 3s\n","454:\tlearn: 0.4684379\ttotal: 2m 32s\tremaining: 3m 2s\n","455:\tlearn: 0.4658195\ttotal: 2m 32s\tremaining: 3m 2s\n","456:\tlearn: 0.4634258\ttotal: 2m 33s\tremaining: 3m 2s\n","457:\tlearn: 0.4611507\ttotal: 2m 33s\tremaining: 3m 1s\n","458:\tlearn: 0.4592438\ttotal: 2m 33s\tremaining: 3m 1s\n","459:\tlearn: 0.4566906\ttotal: 2m 34s\tremaining: 3m 1s\n","460:\tlearn: 0.4543839\ttotal: 2m 34s\tremaining: 3m\n","461:\tlearn: 0.4525985\ttotal: 2m 34s\tremaining: 3m\n","462:\tlearn: 0.4502682\ttotal: 2m 35s\tremaining: 2m 59s\n","463:\tlearn: 0.4483404\ttotal: 2m 35s\tremaining: 2m 59s\n","464:\tlearn: 0.4458596\ttotal: 2m 35s\tremaining: 2m 59s\n","465:\tlearn: 0.4436711\ttotal: 2m 36s\tremaining: 2m 58s\n","466:\tlearn: 0.4422373\ttotal: 2m 36s\tremaining: 2m 58s\n","467:\tlearn: 0.4399019\ttotal: 2m 36s\tremaining: 2m 58s\n","468:\tlearn: 0.4378312\ttotal: 2m 36s\tremaining: 2m 57s\n","469:\tlearn: 0.4354321\ttotal: 2m 37s\tremaining: 2m 57s\n","470:\tlearn: 0.4332538\ttotal: 2m 37s\tremaining: 2m 56s\n","471:\tlearn: 0.4309539\ttotal: 2m 37s\tremaining: 2m 56s\n","472:\tlearn: 0.4297900\ttotal: 2m 38s\tremaining: 2m 56s\n","473:\tlearn: 0.4276175\ttotal: 2m 38s\tremaining: 2m 55s\n","474:\tlearn: 0.4257385\ttotal: 2m 38s\tremaining: 2m 55s\n","475:\tlearn: 0.4240608\ttotal: 2m 39s\tremaining: 2m 55s\n","476:\tlearn: 0.4217945\ttotal: 2m 39s\tremaining: 2m 54s\n","477:\tlearn: 0.4196232\ttotal: 2m 39s\tremaining: 2m 54s\n","478:\tlearn: 0.4178760\ttotal: 2m 40s\tremaining: 2m 54s\n","479:\tlearn: 0.4162317\ttotal: 2m 40s\tremaining: 2m 53s\n","480:\tlearn: 0.4141828\ttotal: 2m 40s\tremaining: 2m 53s\n","481:\tlearn: 0.4127744\ttotal: 2m 41s\tremaining: 2m 53s\n","482:\tlearn: 0.4115229\ttotal: 2m 41s\tremaining: 2m 52s\n","483:\tlearn: 0.4098022\ttotal: 2m 41s\tremaining: 2m 52s\n","484:\tlearn: 0.4080821\ttotal: 2m 42s\tremaining: 2m 52s\n","485:\tlearn: 0.4059683\ttotal: 2m 42s\tremaining: 2m 51s\n","486:\tlearn: 0.4052097\ttotal: 2m 42s\tremaining: 2m 51s\n","487:\tlearn: 0.4035057\ttotal: 2m 43s\tremaining: 2m 51s\n","488:\tlearn: 0.4021541\ttotal: 2m 43s\tremaining: 2m 50s\n","489:\tlearn: 0.4003891\ttotal: 2m 43s\tremaining: 2m 50s\n","490:\tlearn: 0.3982282\ttotal: 2m 44s\tremaining: 2m 50s\n","491:\tlearn: 0.3964995\ttotal: 2m 44s\tremaining: 2m 50s\n","492:\tlearn: 0.3950456\ttotal: 2m 45s\tremaining: 2m 49s\n","493:\tlearn: 0.3931068\ttotal: 2m 45s\tremaining: 2m 49s\n","494:\tlearn: 0.3915463\ttotal: 2m 45s\tremaining: 2m 49s\n","495:\tlearn: 0.3897380\ttotal: 2m 46s\tremaining: 2m 48s\n","496:\tlearn: 0.3880148\ttotal: 2m 46s\tremaining: 2m 48s\n","497:\tlearn: 0.3864193\ttotal: 2m 46s\tremaining: 2m 48s\n","498:\tlearn: 0.3846997\ttotal: 2m 47s\tremaining: 2m 47s\n","499:\tlearn: 0.3831292\ttotal: 2m 47s\tremaining: 2m 47s\n","500:\tlearn: 0.3814766\ttotal: 2m 47s\tremaining: 2m 46s\n","501:\tlearn: 0.3799421\ttotal: 2m 47s\tremaining: 2m 46s\n","502:\tlearn: 0.3788419\ttotal: 2m 48s\tremaining: 2m 46s\n","503:\tlearn: 0.3769383\ttotal: 2m 48s\tremaining: 2m 45s\n","504:\tlearn: 0.3756565\ttotal: 2m 48s\tremaining: 2m 45s\n","505:\tlearn: 0.3746276\ttotal: 2m 49s\tremaining: 2m 45s\n","506:\tlearn: 0.3728135\ttotal: 2m 49s\tremaining: 2m 44s\n","507:\tlearn: 0.3713342\ttotal: 2m 49s\tremaining: 2m 44s\n","508:\tlearn: 0.3696219\ttotal: 2m 50s\tremaining: 2m 43s\n","509:\tlearn: 0.3681053\ttotal: 2m 50s\tremaining: 2m 43s\n","510:\tlearn: 0.3676221\ttotal: 2m 50s\tremaining: 2m 43s\n","511:\tlearn: 0.3669026\ttotal: 2m 51s\tremaining: 2m 43s\n","512:\tlearn: 0.3659112\ttotal: 2m 51s\tremaining: 2m 42s\n","513:\tlearn: 0.3643618\ttotal: 2m 51s\tremaining: 2m 42s\n","514:\tlearn: 0.3628126\ttotal: 2m 52s\tremaining: 2m 42s\n","515:\tlearn: 0.3618073\ttotal: 2m 52s\tremaining: 2m 41s\n","516:\tlearn: 0.3600988\ttotal: 2m 52s\tremaining: 2m 41s\n","517:\tlearn: 0.3586361\ttotal: 2m 53s\tremaining: 2m 41s\n","518:\tlearn: 0.3572360\ttotal: 2m 53s\tremaining: 2m 41s\n","519:\tlearn: 0.3557685\ttotal: 2m 54s\tremaining: 2m 40s\n","520:\tlearn: 0.3544448\ttotal: 2m 54s\tremaining: 2m 40s\n","521:\tlearn: 0.3533715\ttotal: 2m 54s\tremaining: 2m 40s\n","522:\tlearn: 0.3520395\ttotal: 2m 55s\tremaining: 2m 39s\n","523:\tlearn: 0.3516351\ttotal: 2m 55s\tremaining: 2m 39s\n","524:\tlearn: 0.3509887\ttotal: 2m 55s\tremaining: 2m 39s\n","525:\tlearn: 0.3493876\ttotal: 2m 56s\tremaining: 2m 38s\n","526:\tlearn: 0.3480905\ttotal: 2m 56s\tremaining: 2m 38s\n","527:\tlearn: 0.3468491\ttotal: 2m 57s\tremaining: 2m 38s\n","528:\tlearn: 0.3454726\ttotal: 2m 57s\tremaining: 2m 37s\n","529:\tlearn: 0.3438724\ttotal: 2m 57s\tremaining: 2m 37s\n","530:\tlearn: 0.3426516\ttotal: 2m 58s\tremaining: 2m 37s\n","531:\tlearn: 0.3412667\ttotal: 2m 58s\tremaining: 2m 37s\n","532:\tlearn: 0.3396534\ttotal: 2m 58s\tremaining: 2m 36s\n","533:\tlearn: 0.3389224\ttotal: 2m 59s\tremaining: 2m 36s\n","534:\tlearn: 0.3372763\ttotal: 2m 59s\tremaining: 2m 36s\n","535:\tlearn: 0.3362594\ttotal: 2m 59s\tremaining: 2m 35s\n","536:\tlearn: 0.3350668\ttotal: 3m\tremaining: 2m 35s\n","537:\tlearn: 0.3338820\ttotal: 3m\tremaining: 2m 34s\n","538:\tlearn: 0.3332713\ttotal: 3m\tremaining: 2m 34s\n","539:\tlearn: 0.3318533\ttotal: 3m 1s\tremaining: 2m 34s\n","540:\tlearn: 0.3311229\ttotal: 3m 1s\tremaining: 2m 33s\n","541:\tlearn: 0.3299612\ttotal: 3m 1s\tremaining: 2m 33s\n","542:\tlearn: 0.3286067\ttotal: 3m 2s\tremaining: 2m 33s\n","543:\tlearn: 0.3271463\ttotal: 3m 2s\tremaining: 2m 32s\n","544:\tlearn: 0.3258718\ttotal: 3m 2s\tremaining: 2m 32s\n","545:\tlearn: 0.3251918\ttotal: 3m 3s\tremaining: 2m 32s\n","546:\tlearn: 0.3238015\ttotal: 3m 3s\tremaining: 2m 32s\n","547:\tlearn: 0.3224803\ttotal: 3m 3s\tremaining: 2m 31s\n","548:\tlearn: 0.3211943\ttotal: 3m 4s\tremaining: 2m 31s\n","549:\tlearn: 0.3197946\ttotal: 3m 4s\tremaining: 2m 31s\n","550:\tlearn: 0.3185808\ttotal: 3m 5s\tremaining: 2m 30s\n","551:\tlearn: 0.3174794\ttotal: 3m 5s\tremaining: 2m 30s\n","552:\tlearn: 0.3166115\ttotal: 3m 5s\tremaining: 2m 30s\n","553:\tlearn: 0.3152921\ttotal: 3m 6s\tremaining: 2m 29s\n","554:\tlearn: 0.3142978\ttotal: 3m 6s\tremaining: 2m 29s\n","555:\tlearn: 0.3130286\ttotal: 3m 6s\tremaining: 2m 29s\n","556:\tlearn: 0.3117622\ttotal: 3m 6s\tremaining: 2m 28s\n","557:\tlearn: 0.3104419\ttotal: 3m 7s\tremaining: 2m 28s\n","558:\tlearn: 0.3094836\ttotal: 3m 7s\tremaining: 2m 27s\n","559:\tlearn: 0.3082969\ttotal: 3m 7s\tremaining: 2m 27s\n","560:\tlearn: 0.3074017\ttotal: 3m 8s\tremaining: 2m 27s\n","561:\tlearn: 0.3065747\ttotal: 3m 8s\tremaining: 2m 26s\n","562:\tlearn: 0.3057389\ttotal: 3m 8s\tremaining: 2m 26s\n","563:\tlearn: 0.3051739\ttotal: 3m 9s\tremaining: 2m 26s\n","564:\tlearn: 0.3040666\ttotal: 3m 9s\tremaining: 2m 25s\n","565:\tlearn: 0.3029743\ttotal: 3m 9s\tremaining: 2m 25s\n","566:\tlearn: 0.3017188\ttotal: 3m 10s\tremaining: 2m 25s\n","567:\tlearn: 0.3006977\ttotal: 3m 10s\tremaining: 2m 25s\n","568:\tlearn: 0.2995785\ttotal: 3m 11s\tremaining: 2m 24s\n","569:\tlearn: 0.2983033\ttotal: 3m 11s\tremaining: 2m 24s\n","570:\tlearn: 0.2976823\ttotal: 3m 11s\tremaining: 2m 24s\n","571:\tlearn: 0.2966617\ttotal: 3m 12s\tremaining: 2m 23s\n","572:\tlearn: 0.2953927\ttotal: 3m 12s\tremaining: 2m 23s\n","573:\tlearn: 0.2942658\ttotal: 3m 12s\tremaining: 2m 23s\n","574:\tlearn: 0.2931037\ttotal: 3m 13s\tremaining: 2m 22s\n","575:\tlearn: 0.2921538\ttotal: 3m 13s\tremaining: 2m 22s\n","576:\tlearn: 0.2912511\ttotal: 3m 13s\tremaining: 2m 22s\n","577:\tlearn: 0.2905707\ttotal: 3m 14s\tremaining: 2m 21s\n","578:\tlearn: 0.2896005\ttotal: 3m 14s\tremaining: 2m 21s\n","579:\tlearn: 0.2888493\ttotal: 3m 14s\tremaining: 2m 21s\n","580:\tlearn: 0.2878674\ttotal: 3m 15s\tremaining: 2m 20s\n","581:\tlearn: 0.2868354\ttotal: 3m 15s\tremaining: 2m 20s\n","582:\tlearn: 0.2861681\ttotal: 3m 15s\tremaining: 2m 20s\n","583:\tlearn: 0.2850563\ttotal: 3m 16s\tremaining: 2m 19s\n","584:\tlearn: 0.2840216\ttotal: 3m 16s\tremaining: 2m 19s\n","585:\tlearn: 0.2829897\ttotal: 3m 16s\tremaining: 2m 19s\n","586:\tlearn: 0.2819967\ttotal: 3m 17s\tremaining: 2m 18s\n","587:\tlearn: 0.2808261\ttotal: 3m 17s\tremaining: 2m 18s\n","588:\tlearn: 0.2801035\ttotal: 3m 17s\tremaining: 2m 18s\n","589:\tlearn: 0.2790441\ttotal: 3m 18s\tremaining: 2m 17s\n","590:\tlearn: 0.2781146\ttotal: 3m 18s\tremaining: 2m 17s\n","591:\tlearn: 0.2769696\ttotal: 3m 19s\tremaining: 2m 17s\n","592:\tlearn: 0.2759054\ttotal: 3m 19s\tremaining: 2m 16s\n","593:\tlearn: 0.2749891\ttotal: 3m 19s\tremaining: 2m 16s\n","594:\tlearn: 0.2739715\ttotal: 3m 19s\tremaining: 2m 16s\n","595:\tlearn: 0.2728594\ttotal: 3m 20s\tremaining: 2m 15s\n","596:\tlearn: 0.2718885\ttotal: 3m 20s\tremaining: 2m 15s\n","597:\tlearn: 0.2710191\ttotal: 3m 21s\tremaining: 2m 15s\n","598:\tlearn: 0.2699612\ttotal: 3m 21s\tremaining: 2m 14s\n","599:\tlearn: 0.2689194\ttotal: 3m 21s\tremaining: 2m 14s\n","600:\tlearn: 0.2682261\ttotal: 3m 22s\tremaining: 2m 14s\n","601:\tlearn: 0.2677540\ttotal: 3m 22s\tremaining: 2m 13s\n","602:\tlearn: 0.2670800\ttotal: 3m 22s\tremaining: 2m 13s\n","603:\tlearn: 0.2660004\ttotal: 3m 23s\tremaining: 2m 13s\n","604:\tlearn: 0.2652294\ttotal: 3m 23s\tremaining: 2m 12s\n","605:\tlearn: 0.2650624\ttotal: 3m 24s\tremaining: 2m 12s\n","606:\tlearn: 0.2641211\ttotal: 3m 24s\tremaining: 2m 12s\n","607:\tlearn: 0.2632429\ttotal: 3m 24s\tremaining: 2m 12s\n","608:\tlearn: 0.2628480\ttotal: 3m 25s\tremaining: 2m 11s\n","609:\tlearn: 0.2622211\ttotal: 3m 25s\tremaining: 2m 11s\n","610:\tlearn: 0.2612715\ttotal: 3m 25s\tremaining: 2m 11s\n","611:\tlearn: 0.2607040\ttotal: 3m 26s\tremaining: 2m 10s\n","612:\tlearn: 0.2599257\ttotal: 3m 26s\tremaining: 2m 10s\n","613:\tlearn: 0.2589127\ttotal: 3m 27s\tremaining: 2m 10s\n","614:\tlearn: 0.2579507\ttotal: 3m 27s\tremaining: 2m 9s\n","615:\tlearn: 0.2572397\ttotal: 3m 27s\tremaining: 2m 9s\n","616:\tlearn: 0.2562309\ttotal: 3m 28s\tremaining: 2m 9s\n","617:\tlearn: 0.2556745\ttotal: 3m 28s\tremaining: 2m 8s\n","618:\tlearn: 0.2548565\ttotal: 3m 28s\tremaining: 2m 8s\n","619:\tlearn: 0.2542134\ttotal: 3m 28s\tremaining: 2m 8s\n","620:\tlearn: 0.2535919\ttotal: 3m 29s\tremaining: 2m 7s\n","621:\tlearn: 0.2527491\ttotal: 3m 29s\tremaining: 2m 7s\n","622:\tlearn: 0.2524542\ttotal: 3m 29s\tremaining: 2m 6s\n","623:\tlearn: 0.2519476\ttotal: 3m 30s\tremaining: 2m 6s\n","624:\tlearn: 0.2511747\ttotal: 3m 30s\tremaining: 2m 6s\n","625:\tlearn: 0.2503754\ttotal: 3m 30s\tremaining: 2m 5s\n","626:\tlearn: 0.2495279\ttotal: 3m 31s\tremaining: 2m 5s\n","627:\tlearn: 0.2486633\ttotal: 3m 31s\tremaining: 2m 5s\n","628:\tlearn: 0.2477887\ttotal: 3m 31s\tremaining: 2m 5s\n","629:\tlearn: 0.2469431\ttotal: 3m 32s\tremaining: 2m 4s\n","630:\tlearn: 0.2465006\ttotal: 3m 32s\tremaining: 2m 4s\n","631:\tlearn: 0.2456795\ttotal: 3m 32s\tremaining: 2m 3s\n","632:\tlearn: 0.2449228\ttotal: 3m 33s\tremaining: 2m 3s\n","633:\tlearn: 0.2440958\ttotal: 3m 33s\tremaining: 2m 3s\n","634:\tlearn: 0.2434631\ttotal: 3m 33s\tremaining: 2m 2s\n","635:\tlearn: 0.2433047\ttotal: 3m 34s\tremaining: 2m 2s\n","636:\tlearn: 0.2425794\ttotal: 3m 34s\tremaining: 2m 2s\n","637:\tlearn: 0.2417550\ttotal: 3m 34s\tremaining: 2m 1s\n","638:\tlearn: 0.2409997\ttotal: 3m 35s\tremaining: 2m 1s\n","639:\tlearn: 0.2400878\ttotal: 3m 35s\tremaining: 2m 1s\n","640:\tlearn: 0.2392720\ttotal: 3m 35s\tremaining: 2m\n","641:\tlearn: 0.2384763\ttotal: 3m 36s\tremaining: 2m\n","642:\tlearn: 0.2376424\ttotal: 3m 36s\tremaining: 2m\n","643:\tlearn: 0.2367990\ttotal: 3m 36s\tremaining: 1m 59s\n","644:\tlearn: 0.2359904\ttotal: 3m 37s\tremaining: 1m 59s\n","645:\tlearn: 0.2354549\ttotal: 3m 37s\tremaining: 1m 59s\n","646:\tlearn: 0.2349503\ttotal: 3m 38s\tremaining: 1m 58s\n","647:\tlearn: 0.2342637\ttotal: 3m 38s\tremaining: 1m 58s\n","648:\tlearn: 0.2337304\ttotal: 3m 38s\tremaining: 1m 58s\n","649:\tlearn: 0.2329511\ttotal: 3m 39s\tremaining: 1m 57s\n","650:\tlearn: 0.2322489\ttotal: 3m 39s\tremaining: 1m 57s\n","651:\tlearn: 0.2315286\ttotal: 3m 39s\tremaining: 1m 57s\n","652:\tlearn: 0.2309174\ttotal: 3m 40s\tremaining: 1m 57s\n","653:\tlearn: 0.2301740\ttotal: 3m 40s\tremaining: 1m 56s\n","654:\tlearn: 0.2293805\ttotal: 3m 40s\tremaining: 1m 56s\n","655:\tlearn: 0.2287740\ttotal: 3m 41s\tremaining: 1m 56s\n","656:\tlearn: 0.2282200\ttotal: 3m 41s\tremaining: 1m 55s\n","657:\tlearn: 0.2274849\ttotal: 3m 41s\tremaining: 1m 55s\n","658:\tlearn: 0.2267016\ttotal: 3m 42s\tremaining: 1m 55s\n","659:\tlearn: 0.2261475\ttotal: 3m 42s\tremaining: 1m 54s\n","660:\tlearn: 0.2255390\ttotal: 3m 43s\tremaining: 1m 54s\n","661:\tlearn: 0.2249680\ttotal: 3m 43s\tremaining: 1m 54s\n","662:\tlearn: 0.2244853\ttotal: 3m 43s\tremaining: 1m 53s\n","663:\tlearn: 0.2238252\ttotal: 3m 44s\tremaining: 1m 53s\n","664:\tlearn: 0.2234538\ttotal: 3m 44s\tremaining: 1m 53s\n","665:\tlearn: 0.2230525\ttotal: 3m 44s\tremaining: 1m 52s\n","666:\tlearn: 0.2223614\ttotal: 3m 45s\tremaining: 1m 52s\n","667:\tlearn: 0.2216083\ttotal: 3m 45s\tremaining: 1m 52s\n","668:\tlearn: 0.2209284\ttotal: 3m 45s\tremaining: 1m 51s\n","669:\tlearn: 0.2203262\ttotal: 3m 46s\tremaining: 1m 51s\n","670:\tlearn: 0.2196476\ttotal: 3m 46s\tremaining: 1m 51s\n","671:\tlearn: 0.2190706\ttotal: 3m 46s\tremaining: 1m 50s\n","672:\tlearn: 0.2186767\ttotal: 3m 47s\tremaining: 1m 50s\n","673:\tlearn: 0.2180859\ttotal: 3m 47s\tremaining: 1m 50s\n","674:\tlearn: 0.2173786\ttotal: 3m 48s\tremaining: 1m 49s\n","675:\tlearn: 0.2168393\ttotal: 3m 48s\tremaining: 1m 49s\n","676:\tlearn: 0.2162117\ttotal: 3m 48s\tremaining: 1m 49s\n","677:\tlearn: 0.2154985\ttotal: 3m 49s\tremaining: 1m 48s\n","678:\tlearn: 0.2148775\ttotal: 3m 49s\tremaining: 1m 48s\n","679:\tlearn: 0.2141972\ttotal: 3m 49s\tremaining: 1m 48s\n","680:\tlearn: 0.2134520\ttotal: 3m 50s\tremaining: 1m 47s\n","681:\tlearn: 0.2130545\ttotal: 3m 50s\tremaining: 1m 47s\n","682:\tlearn: 0.2123212\ttotal: 3m 50s\tremaining: 1m 47s\n","683:\tlearn: 0.2116380\ttotal: 3m 51s\tremaining: 1m 46s\n","684:\tlearn: 0.2110119\ttotal: 3m 51s\tremaining: 1m 46s\n","685:\tlearn: 0.2104429\ttotal: 3m 51s\tremaining: 1m 46s\n","686:\tlearn: 0.2098265\ttotal: 3m 52s\tremaining: 1m 45s\n","687:\tlearn: 0.2092607\ttotal: 3m 52s\tremaining: 1m 45s\n","688:\tlearn: 0.2087486\ttotal: 3m 53s\tremaining: 1m 45s\n","689:\tlearn: 0.2081845\ttotal: 3m 53s\tremaining: 1m 44s\n","690:\tlearn: 0.2076433\ttotal: 3m 53s\tremaining: 1m 44s\n","691:\tlearn: 0.2071970\ttotal: 3m 54s\tremaining: 1m 44s\n","692:\tlearn: 0.2066444\ttotal: 3m 54s\tremaining: 1m 43s\n","693:\tlearn: 0.2062083\ttotal: 3m 54s\tremaining: 1m 43s\n","694:\tlearn: 0.2056871\ttotal: 3m 55s\tremaining: 1m 43s\n","695:\tlearn: 0.2050422\ttotal: 3m 55s\tremaining: 1m 42s\n","696:\tlearn: 0.2045237\ttotal: 3m 55s\tremaining: 1m 42s\n","697:\tlearn: 0.2042141\ttotal: 3m 56s\tremaining: 1m 42s\n","698:\tlearn: 0.2036187\ttotal: 3m 56s\tremaining: 1m 41s\n","699:\tlearn: 0.2032501\ttotal: 3m 57s\tremaining: 1m 41s\n","700:\tlearn: 0.2026261\ttotal: 3m 57s\tremaining: 1m 41s\n","701:\tlearn: 0.2021475\ttotal: 3m 57s\tremaining: 1m 40s\n","702:\tlearn: 0.2016329\ttotal: 3m 58s\tremaining: 1m 40s\n","703:\tlearn: 0.2011102\ttotal: 3m 58s\tremaining: 1m 40s\n","704:\tlearn: 0.2007751\ttotal: 3m 59s\tremaining: 1m 40s\n","705:\tlearn: 0.2001568\ttotal: 3m 59s\tremaining: 1m 39s\n","706:\tlearn: 0.1995711\ttotal: 3m 59s\tremaining: 1m 39s\n","707:\tlearn: 0.1991947\ttotal: 4m\tremaining: 1m 39s\n","708:\tlearn: 0.1988023\ttotal: 4m\tremaining: 1m 38s\n","709:\tlearn: 0.1982002\ttotal: 4m\tremaining: 1m 38s\n","710:\tlearn: 0.1976823\ttotal: 4m 1s\tremaining: 1m 38s\n","711:\tlearn: 0.1971818\ttotal: 4m 1s\tremaining: 1m 37s\n","712:\tlearn: 0.1967933\ttotal: 4m 1s\tremaining: 1m 37s\n","713:\tlearn: 0.1962998\ttotal: 4m 2s\tremaining: 1m 37s\n","714:\tlearn: 0.1958836\ttotal: 4m 2s\tremaining: 1m 36s\n","715:\tlearn: 0.1954536\ttotal: 4m 3s\tremaining: 1m 36s\n","716:\tlearn: 0.1950523\ttotal: 4m 3s\tremaining: 1m 36s\n","717:\tlearn: 0.1946767\ttotal: 4m 3s\tremaining: 1m 35s\n","718:\tlearn: 0.1941381\ttotal: 4m 4s\tremaining: 1m 35s\n","719:\tlearn: 0.1936688\ttotal: 4m 4s\tremaining: 1m 35s\n","720:\tlearn: 0.1931638\ttotal: 4m 4s\tremaining: 1m 34s\n","721:\tlearn: 0.1925822\ttotal: 4m 5s\tremaining: 1m 34s\n","722:\tlearn: 0.1921061\ttotal: 4m 5s\tremaining: 1m 34s\n","723:\tlearn: 0.1916386\ttotal: 4m 5s\tremaining: 1m 33s\n","724:\tlearn: 0.1913195\ttotal: 4m 6s\tremaining: 1m 33s\n","725:\tlearn: 0.1907791\ttotal: 4m 6s\tremaining: 1m 33s\n","726:\tlearn: 0.1904824\ttotal: 4m 6s\tremaining: 1m 32s\n","727:\tlearn: 0.1900146\ttotal: 4m 7s\tremaining: 1m 32s\n","728:\tlearn: 0.1895192\ttotal: 4m 7s\tremaining: 1m 32s\n","729:\tlearn: 0.1891700\ttotal: 4m 8s\tremaining: 1m 31s\n","730:\tlearn: 0.1886666\ttotal: 4m 8s\tremaining: 1m 31s\n","731:\tlearn: 0.1882726\ttotal: 4m 8s\tremaining: 1m 31s\n","732:\tlearn: 0.1879342\ttotal: 4m 9s\tremaining: 1m 30s\n","733:\tlearn: 0.1874221\ttotal: 4m 9s\tremaining: 1m 30s\n","734:\tlearn: 0.1868611\ttotal: 4m 9s\tremaining: 1m 30s\n","735:\tlearn: 0.1864446\ttotal: 4m 10s\tremaining: 1m 29s\n","736:\tlearn: 0.1859185\ttotal: 4m 10s\tremaining: 1m 29s\n","737:\tlearn: 0.1854106\ttotal: 4m 10s\tremaining: 1m 29s\n","738:\tlearn: 0.1849602\ttotal: 4m 11s\tremaining: 1m 28s\n","739:\tlearn: 0.1844483\ttotal: 4m 11s\tremaining: 1m 28s\n","740:\tlearn: 0.1839346\ttotal: 4m 11s\tremaining: 1m 28s\n","741:\tlearn: 0.1838510\ttotal: 4m 12s\tremaining: 1m 27s\n","742:\tlearn: 0.1833733\ttotal: 4m 12s\tremaining: 1m 27s\n","743:\tlearn: 0.1830050\ttotal: 4m 12s\tremaining: 1m 26s\n","744:\tlearn: 0.1827385\ttotal: 4m 13s\tremaining: 1m 26s\n","745:\tlearn: 0.1826158\ttotal: 4m 13s\tremaining: 1m 26s\n","746:\tlearn: 0.1822468\ttotal: 4m 13s\tremaining: 1m 25s\n","747:\tlearn: 0.1817328\ttotal: 4m 13s\tremaining: 1m 25s\n","748:\tlearn: 0.1812633\ttotal: 4m 14s\tremaining: 1m 25s\n","749:\tlearn: 0.1808098\ttotal: 4m 14s\tremaining: 1m 24s\n","750:\tlearn: 0.1804001\ttotal: 4m 14s\tremaining: 1m 24s\n","751:\tlearn: 0.1800155\ttotal: 4m 15s\tremaining: 1m 24s\n","752:\tlearn: 0.1795463\ttotal: 4m 15s\tremaining: 1m 23s\n","753:\tlearn: 0.1791392\ttotal: 4m 15s\tremaining: 1m 23s\n","754:\tlearn: 0.1786674\ttotal: 4m 16s\tremaining: 1m 23s\n","755:\tlearn: 0.1781746\ttotal: 4m 16s\tremaining: 1m 22s\n","756:\tlearn: 0.1776652\ttotal: 4m 16s\tremaining: 1m 22s\n","757:\tlearn: 0.1774317\ttotal: 4m 17s\tremaining: 1m 22s\n","758:\tlearn: 0.1770383\ttotal: 4m 17s\tremaining: 1m 21s\n","759:\tlearn: 0.1765504\ttotal: 4m 17s\tremaining: 1m 21s\n","760:\tlearn: 0.1762080\ttotal: 4m 17s\tremaining: 1m 21s\n","761:\tlearn: 0.1757733\ttotal: 4m 18s\tremaining: 1m 20s\n","762:\tlearn: 0.1754255\ttotal: 4m 18s\tremaining: 1m 20s\n","763:\tlearn: 0.1750220\ttotal: 4m 18s\tremaining: 1m 19s\n","764:\tlearn: 0.1747115\ttotal: 4m 19s\tremaining: 1m 19s\n","765:\tlearn: 0.1743140\ttotal: 4m 19s\tremaining: 1m 19s\n","766:\tlearn: 0.1738964\ttotal: 4m 20s\tremaining: 1m 19s\n","767:\tlearn: 0.1734299\ttotal: 4m 20s\tremaining: 1m 18s\n","768:\tlearn: 0.1729723\ttotal: 4m 20s\tremaining: 1m 18s\n","769:\tlearn: 0.1725235\ttotal: 4m 21s\tremaining: 1m 18s\n","770:\tlearn: 0.1720436\ttotal: 4m 21s\tremaining: 1m 17s\n","771:\tlearn: 0.1716473\ttotal: 4m 22s\tremaining: 1m 17s\n","772:\tlearn: 0.1712328\ttotal: 4m 22s\tremaining: 1m 17s\n","773:\tlearn: 0.1709684\ttotal: 4m 22s\tremaining: 1m 16s\n","774:\tlearn: 0.1708189\ttotal: 4m 23s\tremaining: 1m 16s\n","775:\tlearn: 0.1707256\ttotal: 4m 23s\tremaining: 1m 16s\n","776:\tlearn: 0.1703134\ttotal: 4m 23s\tremaining: 1m 15s\n","777:\tlearn: 0.1699237\ttotal: 4m 24s\tremaining: 1m 15s\n","778:\tlearn: 0.1695703\ttotal: 4m 24s\tremaining: 1m 15s\n","779:\tlearn: 0.1692099\ttotal: 4m 25s\tremaining: 1m 14s\n","780:\tlearn: 0.1687492\ttotal: 4m 25s\tremaining: 1m 14s\n","781:\tlearn: 0.1683041\ttotal: 4m 25s\tremaining: 1m 14s\n","782:\tlearn: 0.1678840\ttotal: 4m 26s\tremaining: 1m 13s\n","783:\tlearn: 0.1674644\ttotal: 4m 26s\tremaining: 1m 13s\n","784:\tlearn: 0.1671274\ttotal: 4m 26s\tremaining: 1m 13s\n","785:\tlearn: 0.1667082\ttotal: 4m 27s\tremaining: 1m 12s\n","786:\tlearn: 0.1663544\ttotal: 4m 27s\tremaining: 1m 12s\n","787:\tlearn: 0.1659519\ttotal: 4m 27s\tremaining: 1m 12s\n","788:\tlearn: 0.1654968\ttotal: 4m 28s\tremaining: 1m 11s\n","789:\tlearn: 0.1650491\ttotal: 4m 28s\tremaining: 1m 11s\n","790:\tlearn: 0.1647170\ttotal: 4m 29s\tremaining: 1m 11s\n","791:\tlearn: 0.1643109\ttotal: 4m 29s\tremaining: 1m 10s\n","792:\tlearn: 0.1639075\ttotal: 4m 29s\tremaining: 1m 10s\n","793:\tlearn: 0.1634966\ttotal: 4m 29s\tremaining: 1m 10s\n","794:\tlearn: 0.1630739\ttotal: 4m 30s\tremaining: 1m 9s\n","795:\tlearn: 0.1626499\ttotal: 4m 30s\tremaining: 1m 9s\n","796:\tlearn: 0.1622197\ttotal: 4m 30s\tremaining: 1m 8s\n","797:\tlearn: 0.1619519\ttotal: 4m 31s\tremaining: 1m 8s\n","798:\tlearn: 0.1616448\ttotal: 4m 31s\tremaining: 1m 8s\n","799:\tlearn: 0.1615879\ttotal: 4m 31s\tremaining: 1m 7s\n","800:\tlearn: 0.1611893\ttotal: 4m 32s\tremaining: 1m 7s\n","801:\tlearn: 0.1608437\ttotal: 4m 32s\tremaining: 1m 7s\n","802:\tlearn: 0.1604787\ttotal: 4m 32s\tremaining: 1m 6s\n","803:\tlearn: 0.1600361\ttotal: 4m 33s\tremaining: 1m 6s\n","804:\tlearn: 0.1597738\ttotal: 4m 33s\tremaining: 1m 6s\n","805:\tlearn: 0.1593620\ttotal: 4m 33s\tremaining: 1m 5s\n","806:\tlearn: 0.1592419\ttotal: 4m 34s\tremaining: 1m 5s\n","807:\tlearn: 0.1589336\ttotal: 4m 34s\tremaining: 1m 5s\n","808:\tlearn: 0.1586169\ttotal: 4m 34s\tremaining: 1m 4s\n","809:\tlearn: 0.1583356\ttotal: 4m 35s\tremaining: 1m 4s\n","810:\tlearn: 0.1579655\ttotal: 4m 35s\tremaining: 1m 4s\n","811:\tlearn: 0.1575895\ttotal: 4m 35s\tremaining: 1m 3s\n","812:\tlearn: 0.1573742\ttotal: 4m 35s\tremaining: 1m 3s\n","813:\tlearn: 0.1570240\ttotal: 4m 36s\tremaining: 1m 3s\n","814:\tlearn: 0.1566485\ttotal: 4m 36s\tremaining: 1m 2s\n","815:\tlearn: 0.1562718\ttotal: 4m 36s\tremaining: 1m 2s\n","816:\tlearn: 0.1559172\ttotal: 4m 37s\tremaining: 1m 2s\n","817:\tlearn: 0.1556386\ttotal: 4m 37s\tremaining: 1m 1s\n","818:\tlearn: 0.1553198\ttotal: 4m 37s\tremaining: 1m 1s\n","819:\tlearn: 0.1550532\ttotal: 4m 38s\tremaining: 1m 1s\n","820:\tlearn: 0.1546983\ttotal: 4m 38s\tremaining: 1m\n","821:\tlearn: 0.1543405\ttotal: 4m 38s\tremaining: 1m\n","822:\tlearn: 0.1539629\ttotal: 4m 39s\tremaining: 1m\n","823:\tlearn: 0.1535909\ttotal: 4m 39s\tremaining: 59.7s\n","824:\tlearn: 0.1532397\ttotal: 4m 40s\tremaining: 59.4s\n","825:\tlearn: 0.1529870\ttotal: 4m 40s\tremaining: 59.1s\n","826:\tlearn: 0.1526460\ttotal: 4m 40s\tremaining: 58.8s\n","827:\tlearn: 0.1523234\ttotal: 4m 41s\tremaining: 58.4s\n","828:\tlearn: 0.1520311\ttotal: 4m 41s\tremaining: 58.1s\n","829:\tlearn: 0.1517063\ttotal: 4m 41s\tremaining: 57.8s\n","830:\tlearn: 0.1514584\ttotal: 4m 42s\tremaining: 57.4s\n","831:\tlearn: 0.1511315\ttotal: 4m 42s\tremaining: 57.1s\n","832:\tlearn: 0.1508181\ttotal: 4m 42s\tremaining: 56.7s\n","833:\tlearn: 0.1506984\ttotal: 4m 43s\tremaining: 56.4s\n","834:\tlearn: 0.1504006\ttotal: 4m 43s\tremaining: 56s\n","835:\tlearn: 0.1501502\ttotal: 4m 43s\tremaining: 55.7s\n","836:\tlearn: 0.1499948\ttotal: 4m 44s\tremaining: 55.4s\n","837:\tlearn: 0.1496536\ttotal: 4m 44s\tremaining: 55s\n","838:\tlearn: 0.1493501\ttotal: 4m 45s\tremaining: 54.7s\n","839:\tlearn: 0.1490909\ttotal: 4m 45s\tremaining: 54.4s\n","840:\tlearn: 0.1487368\ttotal: 4m 45s\tremaining: 54s\n","841:\tlearn: 0.1484043\ttotal: 4m 46s\tremaining: 53.7s\n","842:\tlearn: 0.1481420\ttotal: 4m 46s\tremaining: 53.4s\n","843:\tlearn: 0.1478185\ttotal: 4m 46s\tremaining: 53s\n","844:\tlearn: 0.1474787\ttotal: 4m 47s\tremaining: 52.7s\n","845:\tlearn: 0.1471910\ttotal: 4m 47s\tremaining: 52.3s\n","846:\tlearn: 0.1468724\ttotal: 4m 47s\tremaining: 52s\n","847:\tlearn: 0.1465219\ttotal: 4m 48s\tremaining: 51.6s\n","848:\tlearn: 0.1462831\ttotal: 4m 48s\tremaining: 51.3s\n","849:\tlearn: 0.1460187\ttotal: 4m 48s\tremaining: 50.9s\n","850:\tlearn: 0.1458439\ttotal: 4m 48s\tremaining: 50.6s\n","851:\tlearn: 0.1455231\ttotal: 4m 49s\tremaining: 50.2s\n","852:\tlearn: 0.1451855\ttotal: 4m 49s\tremaining: 49.9s\n","853:\tlearn: 0.1449474\ttotal: 4m 49s\tremaining: 49.5s\n","854:\tlearn: 0.1447025\ttotal: 4m 50s\tremaining: 49.2s\n","855:\tlearn: 0.1445392\ttotal: 4m 50s\tremaining: 48.8s\n","856:\tlearn: 0.1442253\ttotal: 4m 50s\tremaining: 48.5s\n","857:\tlearn: 0.1439077\ttotal: 4m 50s\tremaining: 48.2s\n","858:\tlearn: 0.1435783\ttotal: 4m 51s\tremaining: 47.8s\n","859:\tlearn: 0.1432956\ttotal: 4m 51s\tremaining: 47.5s\n","860:\tlearn: 0.1430929\ttotal: 4m 51s\tremaining: 47.1s\n","861:\tlearn: 0.1428259\ttotal: 4m 52s\tremaining: 46.8s\n","862:\tlearn: 0.1425447\ttotal: 4m 52s\tremaining: 46.4s\n","863:\tlearn: 0.1423457\ttotal: 4m 52s\tremaining: 46.1s\n","864:\tlearn: 0.1421600\ttotal: 4m 52s\tremaining: 45.7s\n","865:\tlearn: 0.1418636\ttotal: 4m 53s\tremaining: 45.4s\n","866:\tlearn: 0.1416217\ttotal: 4m 53s\tremaining: 45s\n","867:\tlearn: 0.1414547\ttotal: 4m 53s\tremaining: 44.7s\n","868:\tlearn: 0.1411739\ttotal: 4m 54s\tremaining: 44.3s\n","869:\tlearn: 0.1408573\ttotal: 4m 54s\tremaining: 44s\n","870:\tlearn: 0.1406095\ttotal: 4m 54s\tremaining: 43.7s\n","871:\tlearn: 0.1404457\ttotal: 4m 55s\tremaining: 43.3s\n","872:\tlearn: 0.1401787\ttotal: 4m 55s\tremaining: 43s\n","873:\tlearn: 0.1398905\ttotal: 4m 55s\tremaining: 42.7s\n","874:\tlearn: 0.1396599\ttotal: 4m 56s\tremaining: 42.3s\n","875:\tlearn: 0.1393773\ttotal: 4m 56s\tremaining: 42s\n","876:\tlearn: 0.1391062\ttotal: 4m 56s\tremaining: 41.7s\n","877:\tlearn: 0.1387941\ttotal: 4m 57s\tremaining: 41.3s\n","878:\tlearn: 0.1384851\ttotal: 4m 57s\tremaining: 41s\n","879:\tlearn: 0.1381977\ttotal: 4m 58s\tremaining: 40.6s\n","880:\tlearn: 0.1378887\ttotal: 4m 58s\tremaining: 40.3s\n","881:\tlearn: 0.1376893\ttotal: 4m 58s\tremaining: 39.9s\n","882:\tlearn: 0.1375274\ttotal: 4m 58s\tremaining: 39.6s\n","883:\tlearn: 0.1372422\ttotal: 4m 59s\tremaining: 39.3s\n","884:\tlearn: 0.1369545\ttotal: 4m 59s\tremaining: 38.9s\n","885:\tlearn: 0.1367125\ttotal: 4m 59s\tremaining: 38.6s\n","886:\tlearn: 0.1364760\ttotal: 5m\tremaining: 38.2s\n","887:\tlearn: 0.1362069\ttotal: 5m\tremaining: 37.9s\n","888:\tlearn: 0.1359648\ttotal: 5m\tremaining: 37.5s\n","889:\tlearn: 0.1358840\ttotal: 5m\tremaining: 37.2s\n","890:\tlearn: 0.1356010\ttotal: 5m 1s\tremaining: 36.9s\n","891:\tlearn: 0.1353763\ttotal: 5m 1s\tremaining: 36.5s\n","892:\tlearn: 0.1350687\ttotal: 5m 1s\tremaining: 36.2s\n","893:\tlearn: 0.1347799\ttotal: 5m 2s\tremaining: 35.8s\n","894:\tlearn: 0.1345222\ttotal: 5m 2s\tremaining: 35.5s\n","895:\tlearn: 0.1343704\ttotal: 5m 2s\tremaining: 35.1s\n","896:\tlearn: 0.1340894\ttotal: 5m 3s\tremaining: 34.8s\n","897:\tlearn: 0.1338974\ttotal: 5m 3s\tremaining: 34.4s\n","898:\tlearn: 0.1337010\ttotal: 5m 3s\tremaining: 34.1s\n","899:\tlearn: 0.1334150\ttotal: 5m 3s\tremaining: 33.8s\n","900:\tlearn: 0.1331267\ttotal: 5m 4s\tremaining: 33.4s\n","901:\tlearn: 0.1328451\ttotal: 5m 4s\tremaining: 33.1s\n","902:\tlearn: 0.1326726\ttotal: 5m 4s\tremaining: 32.7s\n","903:\tlearn: 0.1324445\ttotal: 5m 5s\tremaining: 32.4s\n","904:\tlearn: 0.1321862\ttotal: 5m 5s\tremaining: 32.1s\n","905:\tlearn: 0.1318905\ttotal: 5m 5s\tremaining: 31.7s\n","906:\tlearn: 0.1316166\ttotal: 5m 6s\tremaining: 31.4s\n","907:\tlearn: 0.1314474\ttotal: 5m 6s\tremaining: 31.1s\n","908:\tlearn: 0.1312282\ttotal: 5m 6s\tremaining: 30.7s\n","909:\tlearn: 0.1309683\ttotal: 5m 7s\tremaining: 30.4s\n","910:\tlearn: 0.1307246\ttotal: 5m 7s\tremaining: 30s\n","911:\tlearn: 0.1305469\ttotal: 5m 7s\tremaining: 29.7s\n","912:\tlearn: 0.1302867\ttotal: 5m 7s\tremaining: 29.3s\n","913:\tlearn: 0.1301534\ttotal: 5m 8s\tremaining: 29s\n","914:\tlearn: 0.1299264\ttotal: 5m 8s\tremaining: 28.7s\n","915:\tlearn: 0.1296882\ttotal: 5m 9s\tremaining: 28.3s\n","916:\tlearn: 0.1295021\ttotal: 5m 9s\tremaining: 28s\n","917:\tlearn: 0.1292368\ttotal: 5m 9s\tremaining: 27.7s\n","918:\tlearn: 0.1290642\ttotal: 5m 10s\tremaining: 27.3s\n","919:\tlearn: 0.1288049\ttotal: 5m 10s\tremaining: 27s\n","920:\tlearn: 0.1285708\ttotal: 5m 10s\tremaining: 26.7s\n","921:\tlearn: 0.1283794\ttotal: 5m 11s\tremaining: 26.3s\n","922:\tlearn: 0.1281043\ttotal: 5m 11s\tremaining: 26s\n","923:\tlearn: 0.1279190\ttotal: 5m 11s\tremaining: 25.6s\n","924:\tlearn: 0.1277018\ttotal: 5m 12s\tremaining: 25.3s\n","925:\tlearn: 0.1275104\ttotal: 5m 12s\tremaining: 25s\n","926:\tlearn: 0.1272381\ttotal: 5m 12s\tremaining: 24.6s\n","927:\tlearn: 0.1269711\ttotal: 5m 13s\tremaining: 24.3s\n","928:\tlearn: 0.1267335\ttotal: 5m 13s\tremaining: 24s\n","929:\tlearn: 0.1265129\ttotal: 5m 14s\tremaining: 23.6s\n","930:\tlearn: 0.1263373\ttotal: 5m 14s\tremaining: 23.3s\n","931:\tlearn: 0.1260897\ttotal: 5m 14s\tremaining: 23s\n","932:\tlearn: 0.1258446\ttotal: 5m 15s\tremaining: 22.6s\n","933:\tlearn: 0.1256090\ttotal: 5m 15s\tremaining: 22.3s\n","934:\tlearn: 0.1253605\ttotal: 5m 15s\tremaining: 21.9s\n","935:\tlearn: 0.1251008\ttotal: 5m 16s\tremaining: 21.6s\n","936:\tlearn: 0.1248720\ttotal: 5m 16s\tremaining: 21.3s\n","937:\tlearn: 0.1247459\ttotal: 5m 16s\tremaining: 20.9s\n","938:\tlearn: 0.1245571\ttotal: 5m 17s\tremaining: 20.6s\n","939:\tlearn: 0.1243489\ttotal: 5m 17s\tremaining: 20.3s\n","940:\tlearn: 0.1241732\ttotal: 5m 17s\tremaining: 19.9s\n","941:\tlearn: 0.1239389\ttotal: 5m 18s\tremaining: 19.6s\n","942:\tlearn: 0.1237575\ttotal: 5m 18s\tremaining: 19.3s\n","943:\tlearn: 0.1235042\ttotal: 5m 18s\tremaining: 18.9s\n","944:\tlearn: 0.1232993\ttotal: 5m 19s\tremaining: 18.6s\n","945:\tlearn: 0.1232270\ttotal: 5m 19s\tremaining: 18.3s\n","946:\tlearn: 0.1230562\ttotal: 5m 20s\tremaining: 17.9s\n","947:\tlearn: 0.1229032\ttotal: 5m 20s\tremaining: 17.6s\n","948:\tlearn: 0.1227347\ttotal: 5m 20s\tremaining: 17.2s\n","949:\tlearn: 0.1225435\ttotal: 5m 21s\tremaining: 16.9s\n","950:\tlearn: 0.1223530\ttotal: 5m 21s\tremaining: 16.6s\n","951:\tlearn: 0.1222083\ttotal: 5m 21s\tremaining: 16.2s\n","952:\tlearn: 0.1220561\ttotal: 5m 22s\tremaining: 15.9s\n","953:\tlearn: 0.1219623\ttotal: 5m 22s\tremaining: 15.6s\n","954:\tlearn: 0.1217305\ttotal: 5m 22s\tremaining: 15.2s\n","955:\tlearn: 0.1215235\ttotal: 5m 23s\tremaining: 14.9s\n","956:\tlearn: 0.1213305\ttotal: 5m 23s\tremaining: 14.5s\n","957:\tlearn: 0.1210953\ttotal: 5m 23s\tremaining: 14.2s\n","958:\tlearn: 0.1209034\ttotal: 5m 24s\tremaining: 13.9s\n","959:\tlearn: 0.1207998\ttotal: 5m 24s\tremaining: 13.5s\n","960:\tlearn: 0.1205644\ttotal: 5m 25s\tremaining: 13.2s\n","961:\tlearn: 0.1203883\ttotal: 5m 25s\tremaining: 12.9s\n","962:\tlearn: 0.1202110\ttotal: 5m 25s\tremaining: 12.5s\n","963:\tlearn: 0.1199625\ttotal: 5m 26s\tremaining: 12.2s\n","964:\tlearn: 0.1197786\ttotal: 5m 26s\tremaining: 11.8s\n","965:\tlearn: 0.1195739\ttotal: 5m 26s\tremaining: 11.5s\n","966:\tlearn: 0.1193864\ttotal: 5m 27s\tremaining: 11.2s\n","967:\tlearn: 0.1192285\ttotal: 5m 27s\tremaining: 10.8s\n","968:\tlearn: 0.1190273\ttotal: 5m 27s\tremaining: 10.5s\n","969:\tlearn: 0.1187952\ttotal: 5m 28s\tremaining: 10.2s\n","970:\tlearn: 0.1187319\ttotal: 5m 28s\tremaining: 9.81s\n","971:\tlearn: 0.1186566\ttotal: 5m 28s\tremaining: 9.47s\n","972:\tlearn: 0.1184223\ttotal: 5m 29s\tremaining: 9.14s\n","973:\tlearn: 0.1182092\ttotal: 5m 29s\tremaining: 8.8s\n","974:\tlearn: 0.1180284\ttotal: 5m 29s\tremaining: 8.46s\n","975:\tlearn: 0.1179827\ttotal: 5m 30s\tremaining: 8.12s\n","976:\tlearn: 0.1177553\ttotal: 5m 30s\tremaining: 7.78s\n","977:\tlearn: 0.1175393\ttotal: 5m 30s\tremaining: 7.44s\n","978:\tlearn: 0.1173284\ttotal: 5m 31s\tremaining: 7.1s\n","979:\tlearn: 0.1171464\ttotal: 5m 31s\tremaining: 6.76s\n","980:\tlearn: 0.1169970\ttotal: 5m 31s\tremaining: 6.42s\n","981:\tlearn: 0.1168131\ttotal: 5m 32s\tremaining: 6.09s\n","982:\tlearn: 0.1166034\ttotal: 5m 32s\tremaining: 5.75s\n","983:\tlearn: 0.1164037\ttotal: 5m 32s\tremaining: 5.41s\n","984:\tlearn: 0.1161766\ttotal: 5m 33s\tremaining: 5.07s\n","985:\tlearn: 0.1159881\ttotal: 5m 33s\tremaining: 4.73s\n","986:\tlearn: 0.1157686\ttotal: 5m 33s\tremaining: 4.39s\n","987:\tlearn: 0.1156140\ttotal: 5m 33s\tremaining: 4.06s\n","988:\tlearn: 0.1154938\ttotal: 5m 34s\tremaining: 3.72s\n","989:\tlearn: 0.1152887\ttotal: 5m 34s\tremaining: 3.38s\n","990:\tlearn: 0.1151191\ttotal: 5m 34s\tremaining: 3.04s\n","991:\tlearn: 0.1149326\ttotal: 5m 35s\tremaining: 2.7s\n","992:\tlearn: 0.1146971\ttotal: 5m 35s\tremaining: 2.37s\n","993:\tlearn: 0.1145258\ttotal: 5m 35s\tremaining: 2.03s\n","994:\tlearn: 0.1143256\ttotal: 5m 36s\tremaining: 1.69s\n","995:\tlearn: 0.1141229\ttotal: 5m 36s\tremaining: 1.35s\n","996:\tlearn: 0.1138956\ttotal: 5m 36s\tremaining: 1.01s\n","997:\tlearn: 0.1137139\ttotal: 5m 37s\tremaining: 676ms\n","998:\tlearn: 0.1135096\ttotal: 5m 37s\tremaining: 338ms\n","999:\tlearn: 0.1132991\ttotal: 5m 37s\tremaining: 0us\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<catboost.core.CatBoostClassifier at 0x7f1c464d0940>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JylZQdk_YLOR","executionInfo":{"status":"ok","timestamp":1607547354617,"user_tz":360,"elapsed":422210,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"7ada491c-0233-4fba-c8d4-228d453480ba"},"source":["from sklearn import metrics\n","\n","# make predictions\n","prediction = model.predict(xtest)\n","\n","print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, prediction))\n","print('Mean Squared Error:', metrics.mean_squared_error(ytest, prediction))\n","print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(ytest, prediction)))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Mean Absolute Error: 3309.9137931034484\n","Mean Squared Error: 37000954.24876847\n","Root Mean Squared Error: 6082.840968558069\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XkkCmtYQZ-jY"},"source":["XGBoost"]},{"cell_type":"code","metadata":{"id":"_Tmwq-KJeEk9","executionInfo":{"status":"ok","timestamp":1607547354618,"user_tz":360,"elapsed":422201,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}}},"source":["import xgboost as xgb"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"HAh8ceDcaDkW","executionInfo":{"status":"ok","timestamp":1607547354619,"user_tz":360,"elapsed":422193,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}}},"source":["param = {\n","    'max_depth': 3,  # the maximum depth of each tree\n","    'eta': 0.3,  # the training step for each iteration\n","    'silent': 1,  # logging mode - quiet\n","    'objective': 'multi:softprob'}\n","num_round = 20  # the number of training iterations"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1yUsi1fQaG-u","executionInfo":{"status":"ok","timestamp":1607547354620,"user_tz":360,"elapsed":422187,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"bdb6076e-aaaf-407d-b308-be42df00ed86"},"source":["from sklearn.datasets import dump_svmlight_file\n","\n","#separate data from label\n","x = train.drop(['num_trips', 'date_of_month'],axis=1)\n","y = train['num_trips']\n","\n","xtrain,xtest,ytrain,ytest = train_test_split(x,y,train_size=0.20,random_state=1236)\n","\n","\n","model = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n","                max_depth = 5, alpha = 10, n_estimators = 10)\n","\n","model.fit(xtrain,ytrain)\n","\n","prediction = model.predict(xtest)\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["[20:55:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vj8wvW3DaJsr","executionInfo":{"status":"ok","timestamp":1607547354621,"user_tz":360,"elapsed":422178,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"41f5f6a1-5f78-435e-cde3-f172a1cdf617"},"source":["print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, prediction))\n","print('Mean Squared Error:', metrics.mean_squared_error(ytest, prediction))\n","print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(ytest, prediction)))\n"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Mean Absolute Error: 3998.4756327215673\n","Mean Squared Error: 42182216.57041434\n","Root Mean Squared Error: 6494.7837970493165\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uw9M0ZjRaMM_"},"source":["Random Forest"]},{"cell_type":"code","metadata":{"id":"A3lzD7rLaJuC","executionInfo":{"status":"ok","timestamp":1607547354784,"user_tz":360,"elapsed":422331,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}}},"source":["from sklearn.ensemble import RandomForestClassifier\n","rclf = RandomForestClassifier()"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"n1frX92pae0Q","executionInfo":{"status":"ok","timestamp":1607547355377,"user_tz":360,"elapsed":422917,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}}},"source":["rclf.fit(xtrain,ytrain)\n","\n","prediction = rclf.predict(xtest)\n"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ro4S12TdUqV6","executionInfo":{"status":"ok","timestamp":1607547355380,"user_tz":360,"elapsed":422912,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"a8ef7b1d-3053-4c86-8636-41f4208043c7"},"source":["print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, prediction))\n","print('Mean Squared Error:', metrics.mean_squared_error(ytest, prediction))\n","print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(ytest, prediction)))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Mean Absolute Error: 5202.753694581281\n","Mean Squared Error: 67575173.43103448\n","Root Mean Squared Error: 8220.411998862008\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"npaxrw_ObiAu"},"source":["Decision Tree Classifier"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JGPjnbO6cdj1","executionInfo":{"status":"ok","timestamp":1607547358615,"user_tz":360,"elapsed":426138,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"467c0916-c744-4b08-eb16-2d31e2f0c08b"},"source":["pip install --upgrade category_encoders"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Collecting category_encoders\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n","\r\u001b[K     |████                            | 10kB 11.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 11.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.1.4)\n","Requirement already satisfied, skipping upgrade: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.5)\n","Requirement already satisfied, skipping upgrade: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n","Requirement already satisfied, skipping upgrade: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.17.0)\n","Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n","Installing collected packages: category-encoders\n","Successfully installed category-encoders-2.2.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zFzJUXwAbhGT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607547359185,"user_tz":360,"elapsed":426698,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"9bfd6e83-71ed-429c-8b35-05dec64756e6"},"source":["import category_encoders as ce\n","encoder = ce.OrdinalEncoder()\n","\n","\n","dt_train = encoder.fit_transform(xtrain)\n","\n","dt_test = encoder.transform(xtest)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"0ekIuLK5cja2","executionInfo":{"status":"ok","timestamp":1607547359545,"user_tz":360,"elapsed":427038,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"6179233a-3632-4851-9669-f34c84130a00"},"source":["dt_train.head()"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>avg_trip_duration</th>\n","      <th>avg_trip_distance</th>\n","      <th>Max_Temperature_F</th>\n","      <th>Avg_Temperature_F</th>\n","      <th>Min_Temperature_F</th>\n","      <th>Max_DewPoint_F</th>\n","      <th>Avg_DewPoint_F</th>\n","      <th>Min_DewPoint_F</th>\n","      <th>Max_Humidity_%</th>\n","      <th>Avg_Humidity_%</th>\n","      <th>Min_Humidity_%</th>\n","      <th>Max_WindSpeed_mph</th>\n","      <th>Avg_WindSpeed_mph</th>\n","      <th>Min_WindSpeed_mph</th>\n","      <th>Max_Pressure_Hg</th>\n","      <th>Avg_Pressure_Hg</th>\n","      <th>Min_Pressure_Hg</th>\n","      <th>Precipitation_inches</th>\n","      <th>year</th>\n","      <th>prev_day_trips</th>\n","      <th>day__Fri</th>\n","      <th>day__Mon</th>\n","      <th>day__Sat</th>\n","      <th>day__Sun</th>\n","      <th>day__Thur</th>\n","      <th>day__Tues</th>\n","      <th>day__Wed</th>\n","      <th>mo__Apr</th>\n","      <th>mo__Aug</th>\n","      <th>mo__Dec</th>\n","      <th>mo__Feb</th>\n","      <th>mo__Jan</th>\n","      <th>mo__Jul</th>\n","      <th>mo__Jun</th>\n","      <th>mo__Mar</th>\n","      <th>mo__May</th>\n","      <th>mo__Nov</th>\n","      <th>mo__Oct</th>\n","      <th>mo__Sept</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1180</th>\n","      <td>1016.339836</td>\n","      <td>60922.328340</td>\n","      <td>97</td>\n","      <td>85.5</td>\n","      <td>73</td>\n","      <td>76</td>\n","      <td>71.5</td>\n","      <td>66</td>\n","      <td>93</td>\n","      <td>66.0</td>\n","      <td>37</td>\n","      <td>14</td>\n","      <td>7.8</td>\n","      <td>0</td>\n","      <td>29.3</td>\n","      <td>29.3</td>\n","      <td>29.2</td>\n","      <td>0.0</td>\n","      <td>2020</td>\n","      <td>39</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>924</th>\n","      <td>782.624589</td>\n","      <td>207259.104707</td>\n","      <td>71</td>\n","      <td>63.2</td>\n","      <td>60</td>\n","      <td>65</td>\n","      <td>59.7</td>\n","      <td>57</td>\n","      <td>93</td>\n","      <td>88.5</td>\n","      <td>78</td>\n","      <td>15</td>\n","      <td>10.4</td>\n","      <td>0</td>\n","      <td>29.7</td>\n","      <td>29.6</td>\n","      <td>29.6</td>\n","      <td>0.0</td>\n","      <td>2020</td>\n","      <td>13504</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>798</th>\n","      <td>1137.106312</td>\n","      <td>4751.219269</td>\n","      <td>77</td>\n","      <td>56.3</td>\n","      <td>34</td>\n","      <td>44</td>\n","      <td>35.0</td>\n","      <td>30</td>\n","      <td>89</td>\n","      <td>51.9</td>\n","      <td>20</td>\n","      <td>18</td>\n","      <td>7.1</td>\n","      <td>0</td>\n","      <td>29.6</td>\n","      <td>29.5</td>\n","      <td>29.4</td>\n","      <td>0.0</td>\n","      <td>2020</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1426</th>\n","      <td>660.051133</td>\n","      <td>8410.227496</td>\n","      <td>81</td>\n","      <td>60.5</td>\n","      <td>41</td>\n","      <td>55</td>\n","      <td>47.7</td>\n","      <td>38</td>\n","      <td>90</td>\n","      <td>67.5</td>\n","      <td>30</td>\n","      <td>14</td>\n","      <td>5.4</td>\n","      <td>0</td>\n","      <td>29.7</td>\n","      <td>29.6</td>\n","      <td>29.6</td>\n","      <td>0.0</td>\n","      <td>2020</td>\n","      <td>55</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>608</th>\n","      <td>742.091837</td>\n","      <td>3306.234694</td>\n","      <td>65</td>\n","      <td>57.8</td>\n","      <td>53</td>\n","      <td>32</td>\n","      <td>27.2</td>\n","      <td>20</td>\n","      <td>40</td>\n","      <td>31.6</td>\n","      <td>21</td>\n","      <td>23</td>\n","      <td>17.3</td>\n","      <td>12</td>\n","      <td>29.6</td>\n","      <td>29.6</td>\n","      <td>29.4</td>\n","      <td>0.0</td>\n","      <td>2019</td>\n","      <td>8484</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      avg_trip_duration  avg_trip_distance  ...  mo__Oct  mo__Sept\n","1180        1016.339836       60922.328340  ...        0         0\n","924          782.624589      207259.104707  ...        0         0\n","798         1137.106312        4751.219269  ...        0         0\n","1426         660.051133        8410.227496  ...        0         0\n","608          742.091837        3306.234694  ...        0         0\n","\n","[5 rows x 39 columns]"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"pCy84bWEcuq7","executionInfo":{"status":"ok","timestamp":1607547359546,"user_tz":360,"elapsed":427026,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}}},"source":["from sklearn.tree import DecisionTreeClassifier"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IjtAB8xNcx_f","executionInfo":{"status":"ok","timestamp":1607547359547,"user_tz":360,"elapsed":427019,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"e1e77e18-1a2f-490d-f5b8-08b6d479eefb"},"source":["model = DecisionTreeClassifier(criterion='MSE', max_depth=3, random_state=0)\n","\n","#def AccuracyTracker(Xtrain,Xtest,ytrain,ytest,n):\n","model = DecisionTreeClassifier(max_leaf_nodes=50,random_state=50)\n","\n","# fit the model\n","model.fit(dt_train, ytrain)\n","\n","\n","#for i in range(2,50):\n","#AccuracyTracker(dt_train,xtest,ytrain,ytest,4)"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n","                       max_depth=None, max_features=None, max_leaf_nodes=50,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, presort='deprecated',\n","                       random_state=50, splitter='best')"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"9_72QUGOc9xu","executionInfo":{"status":"ok","timestamp":1607547359549,"user_tz":360,"elapsed":427011,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}}},"source":["prediction = model.predict(dt_test)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5PWco9UidA_e","executionInfo":{"status":"ok","timestamp":1607547359550,"user_tz":360,"elapsed":427005,"user":{"displayName":"Katherine Wroble","photoUrl":"","userId":"14752184554761099645"}},"outputId":"0fd3ce2a-5810-45af-ec89-d8fe54342415"},"source":["print('Mean Absolute Error:', metrics.mean_absolute_error(ytest, prediction))\n","print('Mean Squared Error:', metrics.mean_squared_error(ytest, prediction))\n","print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(ytest, prediction)))"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Mean Absolute Error: 6104.587438423645\n","Mean Squared Error: 101681458.17610838\n","Root Mean Squared Error: 10083.722436486854\n"],"name":"stdout"}]}]}